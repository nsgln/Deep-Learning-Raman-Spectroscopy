{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "flying-operation",
   "metadata": {},
   "source": [
    "# Fine-tuning experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-immunology",
   "metadata": {},
   "source": [
    "Based on the two notebooks : https://github.com/csho33/bacteria-ID/blob/master/1_reference_finetuning.ipynb & https://github.com/csho33/bacteria-ID/blob/master/3_clinical_finetuning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "loaded-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "t00 = time()\n",
    "import numpy as np\n",
    "import os,sys,re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-portuguese",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "unknown-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load from directory\n",
    "os.chdir(os.getcwd())\n",
    "base_dir = 'Raman_Data/'\n",
    "als_dir = base_dir + 'ALS/'\n",
    "ctrl_dir = base_dir + 'CTRL/'\n",
    "\n",
    "base_dir2 = 'Bacteria_TL'\n",
    "sys.path.append(base_dir2)\n",
    "\n",
    "models = ['pretrained_model.ckpt', 'finetuned_model.ckpt', 'clinical_pretrained_model.ckpt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "advance-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_als = os.listdir(als_dir)\n",
    "all_files_als.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "\n",
    "all_files_ctrl = os.listdir(ctrl_dir)\n",
    "all_files_ctrl.sort(key=lambda f: int(re.sub('\\D', '', f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "veterinary-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(file, dir):\n",
    "    with open(dir + file, 'rt') as fd:\n",
    "        data=[]\n",
    "        line = fd.readline()\n",
    "        nline = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", line)\n",
    "        data.append(nline)\n",
    "        while line:\n",
    "            line=fd.readline()\n",
    "            nline = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", line)\n",
    "            data.append(nline)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "isolated-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[] #actual y of spectra\n",
    "Y=[] # 1 -> als; 0 -> ctrl\n",
    "coord=[] #actual x of spectra\n",
    "\n",
    "sep=[60,78,114,150,194,210,225,241,255,280,299,313,323,333,343,353,363,373,383,393] #Il manque le 227\n",
    "groups=[] #for GROUP K FOLD\n",
    "group=0\n",
    "index=1\n",
    "for f in all_files_als:\n",
    "    data=[]\n",
    "    datab=[]\n",
    "    for e in parse_text(f, als_dir):\n",
    "        if len(e) > 0:\n",
    "            datab.append(float(e[0]))\n",
    "            data.append(float(e[1]))\n",
    "    coord.append(datab)\n",
    "    X.append(data)\n",
    "    Y.append(1)\n",
    "    groups.append(group)\n",
    "    if index in sep:\n",
    "        group+=1\n",
    "    index+=1\n",
    "    \n",
    "sep=[33,76,91,138,149,158,168,178,188,198]\n",
    "index=1\n",
    "for f in all_files_ctrl:\n",
    "    data=[]\n",
    "    datab=[]\n",
    "    for e in parse_text(f, ctrl_dir):\n",
    "        if len(e) > 0:\n",
    "            datab.append(float(e[0]))\n",
    "            data.append(float(e[1]))\n",
    "    coord.append(datab)\n",
    "    X.append(data)\n",
    "    Y.append(0)\n",
    "    groups.append(group)\n",
    "    if index in sep:\n",
    "        group+=1\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "curious-advertising",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(591, 1174) (591,)\n"
     ]
    }
   ],
   "source": [
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "groups=np.array(groups)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "certain-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "    for j in range (len(X[i])):\n",
    "        if(X[i][j] < 0):\n",
    "            X[i][j] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-thompson",
   "metadata": {},
   "source": [
    "## Split our dataset into a finetunable set and a full test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-carpet",
   "metadata": {},
   "source": [
    "First, we decide to split our dataset into :\n",
    "1) a \"finetunable\" set for finetune the pretrained model on our data\n",
    "\n",
    "2) a \"full test\" set i.e the left over patients to test our resulting finetuned model\n",
    "\n",
    "The split ratio is 2/3 -> 20 patients for finetune (12 ALS & 8 CTRL) and 10 for test (8 ALS & 2 CTRL). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "documentary-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(num_als, num_ctrl):\n",
    "    patient_idxs_finetune = []\n",
    "\n",
    "    x = list(range(0, 20))\n",
    "    patient_idxs_finetune = random.sample(x,num_als)\n",
    "    patient_idxs_test = [i for i in x if i not in patient_idxs_finetune]\n",
    "\n",
    "    x2 = list(range(20, 30))\n",
    "    patient_idxs_finetune += random.sample(x2,num_ctrl)\n",
    "    patient_idxs_test += [i for i in x2 if i not in patient_idxs_finetune]\n",
    "\n",
    "    #Shuffle to avoid implicit leakage (1 the firsts and 0 the lasts)\n",
    "    random.shuffle(patient_idxs_finetune)\n",
    "    random.shuffle(patient_idxs_test)\n",
    "    return patient_idxs_finetune, patient_idxs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "recovered-liverpool",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 [9, 15, 4, 14, 19, 17, 20, 23, 26, 29, 28, 5, 25, 7, 21, 24, 1, 2, 13, 18]\n",
      "10 [8, 12, 11, 27, 6, 10, 16, 0, 22, 3]\n"
     ]
    }
   ],
   "source": [
    "#Some test to be sure\n",
    "patient_idxs_finetune, patient_idxs_test = split_dataset(12, 8)\n",
    "print(len(patient_idxs_finetune), patient_idxs_finetune)\n",
    "print(len(patient_idxs_test), patient_idxs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-database",
   "metadata": {},
   "source": [
    "## Load ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "intended-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import ResNet\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "juvenile-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN parameters\n",
    "layers = 6\n",
    "hidden_size = 100\n",
    "block_size = 2\n",
    "hidden_sizes = [hidden_size] * layers\n",
    "num_blocks = [block_size] * layers\n",
    "input_dim = 1174\n",
    "in_channels = 64\n",
    "n_classes = 2 # instead of 30, we use the 2 empiric groupings\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '{}'.format(0)\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "universal-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove last layers\n",
    "def removekey(d, listofkeys):\n",
    "    r = dict(d)\n",
    "    for key in listofkeys:\n",
    "        print('key: {} is removed'.format(key))\n",
    "        r.pop(key)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "former-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(n=0):\n",
    "    cnn = ResNet(hidden_sizes, num_blocks, input_dim=input_dim,\n",
    "                    in_channels=in_channels, n_classes=n_classes)\n",
    "    if cuda: cnn.cuda()\n",
    "\n",
    "    checkpoint = torch.load(base_dir2 + '/' + models[n], map_location=lambda storage, loc: storage)\n",
    "    mod_weights = removekey(checkpoint, ['linear.weight', 'linear.bias'])\n",
    "    cnn.load_state_dict(mod_weights, strict=False)\n",
    "    return cnn, mod_weights, checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-liquid",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-middle",
   "metadata": {},
   "source": [
    "### Custom Train/Val/Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-charm",
   "metadata": {},
   "source": [
    "Based on the \"clinical\" notebook we decide to implement a custom method of train/val/test split : the 20 patients are grouped into 4 sub-groups. The first 3 patients of each group are assigned to the training set, the 4th to the validation set and the 5th into the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "ambient-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20 patients into 4 groups of 5 patients\n",
    "def group_patients(patient_idxs_finetune):\n",
    "    patient_idxs = []\n",
    "    x = patient_idxs_finetune\n",
    "    for i in range(4):\n",
    "        l = random.sample(x,5)\n",
    "        patient_idxs.append(l)\n",
    "        x = [i for i in x if i not in l]\n",
    "    return patient_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "coordinated-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_idxs = group_patients(patient_idxs_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "matched-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample train/val/te spectra -> each group [train, train, train, val, test]\n",
    "def custom_split_finetuning(patient_idxs):\n",
    "    idx_tr, idx_val, idx_te = [], [], []\n",
    "    for group_idx, patient_list in enumerate(patient_idxs):\n",
    "        print('Group {} patients'.format(group_idx))\n",
    "        print(' Tr: {}'.format(patient_list[:3]))\n",
    "        print(' Val: {}'.format(patient_list[3]))\n",
    "        print(' Te : {}'.format(patient_list[4]))\n",
    "        for j, patient in enumerate(patient_list):\n",
    "            l= np.where(groups == patient)\n",
    "            start_idx = l[0][0]\n",
    "            end_idx = l[0][len(l[0])-1]\n",
    "            idx_range = list(range(start_idx, end_idx+1))\n",
    "            np.random.shuffle(idx_range) #-> do we shuffle ? \n",
    "            print(patient, idx_range, len(idx_range))\n",
    "            if j < 3:\n",
    "                idx_tr.extend(idx_range)\n",
    "            elif j ==3:\n",
    "                idx_val.extend(idx_range)\n",
    "            else:\n",
    "                idx_te.extend(idx_range)\n",
    "    return idx_tr, idx_val, idx_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "environmental-roots",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0 patients\n",
      " Tr: [5, 9, 4]\n",
      " Val: 24\n",
      " Te : 13\n",
      "5 [201, 203, 204, 202, 209, 195, 196, 197, 198, 200, 194, 206, 207, 199, 208, 205] 16\n",
      "9 [262, 258, 269, 259, 275, 272, 266, 279, 264, 273, 265, 274, 257, 268, 261, 271, 278, 256, 267, 260, 270, 276, 255, 277, 263] 25\n",
      "4 [179, 165, 170, 191, 156, 152, 167, 175, 158, 178, 183, 193, 159, 162, 190, 169, 172, 173, 161, 154, 192, 160, 189, 151, 168, 150, 187, 171, 153, 164, 181, 177, 155, 184, 174, 185, 166, 182, 176, 188, 163, 186, 157, 180] 44\n",
      "24 [534, 540, 533, 532, 537, 536, 541, 531, 539, 538, 535] 11\n",
      "13 [331, 330, 325, 323, 324, 332, 326, 329, 328, 327] 10\n",
      "Group 1 patients\n",
      " Tr: [25, 1, 23]\n",
      " Val: 18\n",
      " Te : 17\n",
      "25 [547, 548, 543, 542, 545, 546, 549, 544, 550] 9\n",
      "1 [63, 71, 60, 74, 75, 66, 61, 69, 70, 73, 65, 67, 68, 64, 72, 62, 77, 76] 18\n",
      "23 [508, 490, 487, 506, 521, 498, 489, 515, 496, 524, 525, 516, 492, 530, 510, 505, 501, 528, 485, 523, 514, 491, 494, 507, 518, 513, 486, 526, 504, 527, 509, 499, 520, 488, 512, 502, 517, 493, 519, 522, 500, 503, 529, 484, 497, 495, 511] 47\n",
      "18 [378, 381, 380, 382, 374, 377, 379, 375, 376, 373] 10\n",
      "17 [363, 370, 366, 369, 365, 372, 371, 367, 368, 364] 10\n",
      "Group 2 patients\n",
      " Tr: [19, 14, 29]\n",
      " Val: 20\n",
      " Te : 21\n",
      "19 [386, 391, 384, 389, 390, 387, 388, 392, 385, 383] 10\n",
      "14 [334, 339, 342, 333, 335, 336, 341, 340, 338, 337] 10\n",
      "29 [584, 582, 581, 588, 589, 586, 590, 587, 585, 583] 10\n",
      "20 [395, 400, 423, 406, 405, 425, 410, 409, 414, 404, 402, 398, 411, 418, 396, 421, 417, 420, 397, 424, 415, 419, 413, 393, 416, 412, 399, 408, 394, 403, 407, 401, 422] 33\n",
      "21 [436, 453, 451, 439, 432, 468, 442, 462, 443, 438, 446, 465, 447, 427, 431, 430, 450, 460, 426, 458, 464, 454, 428, 448, 459, 466, 456, 455, 452, 445, 463, 461, 444, 467, 433, 434, 437, 449, 435, 457, 440, 429, 441] 43\n",
      "Group 3 patients\n",
      " Tr: [2, 7, 28]\n",
      " Val: 15\n",
      " Te : 26\n",
      "2 [109, 104, 87, 110, 90, 113, 82, 85, 83, 80, 92, 94, 105, 98, 100, 81, 79, 84, 88, 101, 96, 78, 89, 108, 95, 99, 93, 111, 102, 103, 86, 91, 112, 107, 106, 97] 36\n",
      "7 [225, 228, 229, 240, 236, 235, 239, 233, 237, 230, 234, 227, 226, 232, 231, 238] 16\n",
      "28 [578, 579, 572, 575, 573, 571, 576, 574, 577, 580] 10\n",
      "15 [351, 349, 345, 346, 347, 350, 352, 344, 348, 343] 10\n",
      "26 [556, 559, 558, 554, 551, 552, 557, 560, 553, 555] 10\n",
      "251\n",
      "64\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "#Outputs len\n",
    "idx_tr, idx_val, idx_te = custom_split_finetuning(patient_idxs)\n",
    "print(len(idx_tr))\n",
    "print(len(idx_val))\n",
    "print(len(idx_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-australia",
   "metadata": {},
   "source": [
    "## Finetuning based on custom split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "presidential-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import spectral_dataloader\n",
    "from training import run_epoch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "abroad-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune CNN\n",
    "def finetune(cnn, idx_tr, idx_val, idx_te):\n",
    "    epochs = 1\n",
    "    batch_size = 10\n",
    "    t0 = time()\n",
    "    # Set up Adam optimizer\n",
    "    optimizer = optim.Adam(cnn.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
    "    # Set up dataloaders\n",
    "    dl_tr = spectral_dataloader(X, Y, idxs=idx_tr,\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "    dl_val = spectral_dataloader(X, Y, idxs=idx_val,\n",
    "        batch_size=batch_size, shuffle=False)\n",
    "    dl_te = spectral_dataloader(X, Y, idxs=idx_te,\n",
    "        batch_size=batch_size, shuffle=False)\n",
    "    # Fine-tune CNN for first fold\n",
    "    best_val = 0\n",
    "    no_improvement = 0\n",
    "    max_no_improvement = 5\n",
    "    print('Starting fine-tuning!')\n",
    "    for epoch in range(epochs):\n",
    "        print(' Epoch {}: {:0.2f}s'.format(epoch+1, time()-t0))\n",
    "        # Train\n",
    "        acc_tr, loss_tr = run_epoch(epoch, cnn, dl_tr, cuda,\n",
    "            training=True, optimizer=optimizer)\n",
    "        print('  Train acc: {:0.2f}'.format(acc_tr))\n",
    "        # Val\n",
    "        acc_val, loss_val = run_epoch(epoch, cnn, dl_val, cuda,\n",
    "            training=False, optimizer=optimizer)\n",
    "        print('  Val acc: {:0.2f}'.format(acc_val))\n",
    "        # Test\n",
    "        acc_te, loss_te = run_epoch(epoch, cnn, dl_te, cuda,\n",
    "            training=False, optimizer=optimizer)\n",
    "        print('  Test acc: {:0.2f}'.format(acc_te))\n",
    "        # Check performance for early stopping\n",
    "        if acc_val > best_val or epoch == 0:\n",
    "            best_val = acc_val\n",
    "            no_improvement = 0\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "        if no_improvement >= max_no_improvement:\n",
    "            print('Finished after {} epochs!'.format(epoch+1))\n",
    "            break\n",
    "    print('Finished: {:0.2f}s'.format(time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-stock",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "greek-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import get_predictions\n",
    "from scipy import stats\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "little-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1/ Getting test indices\n",
    "def get_test_indices(patient_idxs_test):\n",
    "    idx_te = []\n",
    "    for group_idx in patient_idxs_test:\n",
    "        l= np.where(groups == group_idx)\n",
    "        start_idx = l[0][0]\n",
    "        end_idx = l[0][len(l[0])-1]\n",
    "        idx_te += list(range(start_idx, end_idx+1))\n",
    "    return idx_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "enhanced-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(cnn, idx_te):\n",
    "    #1/ Predicting on finetuned model\n",
    "    dl_te = spectral_dataloader(X, Y, idxs=idx_te,\n",
    "        batch_size=batch_size, shuffle=False)\n",
    "    #t0 = time()\n",
    "    y_hat = get_predictions(cnn, dl_te, cuda)\n",
    "    #print('Finished: {:0.2f}s'.format(time()-t0))\n",
    "    #2/ Getting the right Y indices for comparing\n",
    "    Y_l = []\n",
    "    for i in range(len(Y)):\n",
    "        if i in idx_te:\n",
    "            Y_l.append(Y[i])\n",
    "    #3/ Computing accuracy and std\n",
    "    acc = (y_hat == Y_l).mean()\n",
    "    print('Accuracy: {:0.1f}%'.format(100*acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-diesel",
   "metadata": {},
   "source": [
    "## Get average accuracy and std on finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "placed-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(num_model, idx_tr, idx_val, idx_te, fn_idx_te):\n",
    "    list_acc=[]\n",
    "    #Average on 10 times\n",
    "    for i in range(10):\n",
    "        print(i+1)\n",
    "        #Load model\n",
    "        cnn, _, _ = load_model(num_model)\n",
    "        #finetune it owith custom split\n",
    "        finetune(cnn, idx_tr, idx_val, idx_te)\n",
    "        #get accuracy to make an average and std on test set\n",
    "        list_acc.append(predict(cnn, fn_idx_te))\n",
    "    return list_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-wheel",
   "metadata": {},
   "source": [
    "## Trials :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-malaysia",
   "metadata": {},
   "source": [
    "Distribution of 12 ALS & 8 CTRL :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "adjusted-understanding",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0 patients\n",
      " Tr: [18, 4, 11]\n",
      " Val: 17\n",
      " Te : 29\n",
      "18 [375, 376, 380, 382, 379, 378, 377, 381, 374, 373] 10\n",
      "4 [171, 187, 150, 154, 186, 151, 170, 156, 152, 158, 161, 160, 153, 166, 189, 188, 176, 172, 167, 190, 173, 178, 192, 164, 182, 191, 181, 159, 180, 162, 168, 163, 183, 155, 184, 175, 185, 157, 174, 179, 165, 169, 193, 177] 44\n",
      "11 [302, 304, 300, 303, 312, 301, 308, 311, 299, 305, 306, 309, 307, 310] 14\n",
      "17 [368, 369, 367, 365, 371, 366, 364, 363, 370, 372] 10\n",
      "29 [590, 585, 581, 584, 588, 587, 582, 583, 589, 586] 10\n",
      "Group 1 patients\n",
      " Tr: [25, 20, 1]\n",
      " Val: 15\n",
      " Te : 13\n",
      "25 [545, 544, 549, 542, 543, 547, 548, 550, 546] 9\n",
      "20 [425, 406, 396, 419, 394, 415, 397, 400, 401, 395, 421, 417, 393, 424, 409, 407, 405, 420, 416, 412, 422, 418, 410, 402, 404, 411, 414, 413, 408, 423, 398, 399, 403] 33\n",
      "1 [64, 76, 69, 71, 63, 62, 66, 73, 67, 75, 65, 72, 60, 74, 61, 77, 70, 68] 18\n",
      "15 [343, 346, 345, 347, 350, 344, 348, 349, 351, 352] 10\n",
      "13 [323, 324, 328, 332, 329, 331, 327, 326, 330, 325] 10\n",
      "Group 2 patients\n",
      " Tr: [27, 21, 23]\n",
      " Val: 3\n",
      " Te : 14\n",
      "27 [565, 561, 570, 562, 567, 566, 569, 563, 564, 568] 10\n",
      "21 [432, 445, 441, 465, 437, 451, 443, 435, 455, 427, 438, 467, 447, 426, 449, 446, 444, 458, 456, 460, 440, 468, 439, 430, 454, 466, 463, 428, 448, 433, 461, 442, 453, 464, 434, 450, 459, 429, 457, 462, 436, 452, 431] 43\n",
      "23 [519, 487, 488, 527, 486, 524, 495, 517, 525, 529, 494, 485, 509, 506, 528, 513, 504, 497, 520, 501, 530, 503, 516, 499, 521, 498, 518, 511, 491, 484, 508, 507, 514, 493, 522, 515, 500, 502, 490, 526, 496, 510, 492, 489, 505, 523, 512] 47\n",
      "3 [123, 135, 119, 122, 124, 131, 116, 144, 114, 140, 136, 129, 117, 126, 142, 138, 147, 149, 145, 139, 118, 120, 128, 143, 115, 146, 130, 137, 134, 121, 132, 125, 127, 141, 133, 148] 36\n",
      "14 [341, 334, 336, 335, 338, 340, 337, 333, 342, 339] 10\n",
      "Group 3 patients\n",
      " Tr: [6, 9, 28]\n",
      " Val: 2\n",
      " Te : 24\n",
      "6 [215, 216, 223, 214, 217, 211, 224, 222, 220, 218, 212, 219, 221, 213, 210] 15\n",
      "9 [260, 268, 278, 272, 267, 261, 266, 273, 271, 263, 258, 265, 262, 255, 257, 275, 259, 277, 269, 264, 279, 276, 256, 274, 270] 25\n",
      "28 [579, 576, 572, 571, 578, 574, 575, 573, 577, 580] 10\n",
      "2 [87, 103, 90, 107, 113, 104, 86, 81, 99, 108, 106, 98, 95, 101, 78, 93, 91, 100, 84, 88, 97, 82, 111, 96, 105, 112, 109, 94, 92, 85, 110, 89, 79, 80, 83, 102] 36\n",
      "24 [540, 531, 534, 539, 536, 535, 533, 532, 538, 537, 541] 11\n"
     ]
    }
   ],
   "source": [
    "num_als=12\n",
    "num_ctrl = 8\n",
    "patient_idxs_finetune, patient_idxs_test = split_dataset(num_als, num_ctrl)\n",
    "patient_idxs = group_patients(patient_idxs_finetune)\n",
    "idx_tr, idx_val, idx_te = custom_split_finetuning(patient_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "norman-leeds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples to train the finetune model :  278  -> ALS :  126 , CTRL :  152\n",
      "Number of samples to validate the finetune model :  92  -> ALS :  92 , CTRL :  0\n",
      "Number of samples to test the finetune model :  41  -> ALS :  20 , CTRL :  21\n"
     ]
    }
   ],
   "source": [
    "n1 = len([i for i in idx_tr if i < 393])\n",
    "n2 = len([i for i in idx_val if i < 393])\n",
    "n3 = len([i for i in idx_te if i < 393])\n",
    "print(\"Number of samples to train the finetune model : \", len(idx_tr), \" -> ALS : \", n1, \", CTRL : \", len(idx_tr)-n1)\n",
    "print(\"Number of samples to validate the finetune model : \", len(idx_val), \" -> ALS : \", n2, \", CTRL : \", len(idx_val)-n2)\n",
    "print(\"Number of samples to test the finetune model : \", len(idx_te), \" -> ALS : \", n3, \", CTRL : \", len(idx_te)-n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "light-cliff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples to test :  180  -> ALS :  155 , CTRL :  25\n"
     ]
    }
   ],
   "source": [
    "fn_idx_te = get_test_indices(patient_idxs_test)\n",
    "m= len([i for i in fn_idx_te if i < 393])\n",
    "print(\"Number of samples to test : \", len(fn_idx_te), \" -> ALS : \", m, \", CTRL : \", len(fn_idx_te)-m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-stream",
   "metadata": {},
   "source": [
    "- pretrained_model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "interior-bridal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 83.81\n",
      "  Val acc: 100.00\n",
      "  Test acc: 100.00\n",
      "Finished: 7.53s\n",
      "Accuracy: 72.8%\n",
      "2\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 83.81\n",
      "  Val acc: 100.00\n",
      "  Test acc: 97.56\n",
      "Finished: 7.42s\n",
      "Accuracy: 66.7%\n",
      "3\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 79.14\n",
      "  Val acc: 94.57\n",
      "  Test acc: 100.00\n",
      "Finished: 7.38s\n",
      "Accuracy: 65.6%\n",
      "4\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 80.22\n",
      "  Val acc: 100.00\n",
      "  Test acc: 100.00\n",
      "Finished: 7.34s\n",
      "Accuracy: 65.0%\n",
      "5\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 81.29\n",
      "  Val acc: 100.00\n",
      "  Test acc: 97.56\n",
      "Finished: 7.37s\n",
      "Accuracy: 68.9%\n",
      "6\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 83.09\n",
      "  Val acc: 100.00\n",
      "  Test acc: 100.00\n",
      "Finished: 7.40s\n",
      "Accuracy: 66.1%\n",
      "7\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 85.25\n",
      "  Val acc: 100.00\n",
      "  Test acc: 95.12\n",
      "Finished: 7.34s\n",
      "Accuracy: 72.8%\n",
      "8\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 85.25\n",
      "  Val acc: 89.13\n",
      "  Test acc: 100.00\n",
      "Finished: 7.33s\n",
      "Accuracy: 63.9%\n",
      "9\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 83.81\n",
      "  Val acc: 98.91\n",
      "  Test acc: 100.00\n",
      "Finished: 7.36s\n",
      "Accuracy: 66.1%\n",
      "10\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 81.29\n",
      "  Val acc: 98.91\n",
      "  Test acc: 100.00\n",
      "Finished: 7.34s\n",
      "Accuracy: 70.0%\n",
      "0.6777777777777778\n",
      "0.03012320380383546\n"
     ]
    }
   ],
   "source": [
    "list_acc = results(0, idx_tr, idx_val, idx_te, fn_idx_te)\n",
    "print(mean(list_acc))\n",
    "print(np.std(list_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-filter",
   "metadata": {},
   "source": [
    "- finetuned_model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "integrated-celtic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 83.45\n",
      "  Val acc: 100.00\n",
      "  Test acc: 100.00\n",
      "Finished: 7.40s\n",
      "Accuracy: 64.4%\n",
      "2\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 87.41\n",
      "  Val acc: 100.00\n",
      "  Test acc: 100.00\n",
      "Finished: 7.30s\n",
      "Accuracy: 62.8%\n",
      "3\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 85.61\n",
      "  Val acc: 86.96\n",
      "  Test acc: 100.00\n",
      "Finished: 7.32s\n",
      "Accuracy: 62.2%\n",
      "4\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 84.89\n",
      "  Val acc: 100.00\n",
      "  Test acc: 100.00\n",
      "Finished: 7.39s\n",
      "Accuracy: 68.3%\n",
      "5\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 85.61\n",
      "  Val acc: 98.91\n",
      "  Test acc: 100.00\n",
      "Finished: 7.38s\n",
      "Accuracy: 64.4%\n",
      "6\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 84.89\n",
      "  Val acc: 100.00\n",
      "  Test acc: 100.00\n",
      "Finished: 7.36s\n",
      "Accuracy: 70.0%\n",
      "7\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 87.41\n",
      "  Val acc: 100.00\n",
      "  Test acc: 100.00\n",
      "Finished: 7.30s\n",
      "Accuracy: 65.0%\n",
      "8\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 80.22\n",
      "  Val acc: 67.39\n",
      "  Test acc: 100.00\n",
      "Finished: 7.37s\n",
      "Accuracy: 63.3%\n",
      "9\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 83.81\n",
      "  Val acc: 100.00\n",
      "  Test acc: 97.56\n",
      "Finished: 7.31s\n",
      "Accuracy: 68.9%\n",
      "10\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 86.69\n",
      "  Val acc: 98.91\n",
      "  Test acc: 97.56\n",
      "Finished: 7.54s\n",
      "Accuracy: 68.3%\n",
      "0.6577777777777778\n",
      "0.02689715208202267\n"
     ]
    }
   ],
   "source": [
    "list_acc = results(1, idx_tr, idx_val, idx_te, fn_idx_te)\n",
    "print(mean(list_acc))\n",
    "print(np.std(list_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-progress",
   "metadata": {},
   "source": [
    "- clinical_pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "raised-reference",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 78.42\n",
      "  Val acc: 100.00\n",
      "  Test acc: 100.00\n",
      "Finished: 7.97s\n",
      "Accuracy: 66.1%\n",
      "2\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 79.86\n",
      "  Val acc: 86.96\n",
      "  Test acc: 100.00\n",
      "Finished: 7.35s\n",
      "Accuracy: 67.8%\n",
      "3\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 83.09\n",
      "  Val acc: 98.91\n",
      "  Test acc: 100.00\n",
      "Finished: 7.38s\n",
      "Accuracy: 71.7%\n",
      "4\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 82.37\n",
      "  Val acc: 100.00\n",
      "  Test acc: 95.12\n",
      "Finished: 7.27s\n",
      "Accuracy: 73.3%\n",
      "5\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 85.97\n",
      "  Val acc: 98.91\n",
      "  Test acc: 100.00\n",
      "Finished: 7.32s\n",
      "Accuracy: 68.9%\n",
      "6\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 83.81\n",
      "  Val acc: 100.00\n",
      "  Test acc: 95.12\n",
      "Finished: 7.31s\n",
      "Accuracy: 71.1%\n",
      "7\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 80.58\n",
      "  Val acc: 81.52\n",
      "  Test acc: 100.00\n",
      "Finished: 7.28s\n",
      "Accuracy: 67.8%\n",
      "8\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 85.25\n",
      "  Val acc: 91.30\n",
      "  Test acc: 100.00\n",
      "Finished: 7.30s\n",
      "Accuracy: 66.7%\n",
      "9\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 83.81\n",
      "  Val acc: 100.00\n",
      "  Test acc: 100.00\n",
      "Finished: 7.34s\n",
      "Accuracy: 68.9%\n",
      "10\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 84.89\n",
      "  Val acc: 100.00\n",
      "  Test acc: 100.00\n",
      "Finished: 7.44s\n",
      "Accuracy: 71.1%\n",
      "0.6933333333333334\n",
      "0.022470831573507426\n"
     ]
    }
   ],
   "source": [
    "list_acc = results(2, idx_tr, idx_val, idx_te, fn_idx_te)\n",
    "print(mean(list_acc))\n",
    "print(np.std(list_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-reunion",
   "metadata": {},
   "source": [
    "Distribution of 15 ALS & 5 CTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "worst-chick",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0 patients\n",
      " Tr: [0, 10, 21]\n",
      " Val: 12\n",
      " Te : 14\n",
      "0 [8, 21, 38, 48, 32, 10, 45, 7, 33, 11, 12, 55, 2, 49, 54, 30, 46, 59, 35, 25, 23, 22, 52, 53, 56, 43, 39, 47, 18, 36, 50, 4, 31, 51, 34, 29, 15, 9, 37, 13, 5, 27, 6, 26, 16, 17, 1, 14, 24, 57, 3, 58, 40, 0, 19, 44, 28, 41, 20, 42] 60\n",
      "10 [291, 286, 289, 283, 288, 280, 285, 297, 296, 287, 294, 282, 298, 290, 292, 293, 295, 281, 284] 19\n",
      "21 [430, 445, 437, 457, 426, 444, 443, 441, 456, 428, 448, 439, 468, 466, 451, 433, 442, 438, 459, 465, 446, 427, 460, 431, 467, 458, 464, 463, 447, 462, 434, 440, 453, 450, 436, 455, 435, 432, 449, 461, 454, 452, 429] 43\n",
      "12 [314, 321, 318, 319, 322, 317, 316, 320, 313, 315] 10\n",
      "14 [334, 333, 338, 341, 342, 336, 335, 337, 339, 340] 10\n",
      "Group 1 patients\n",
      " Tr: [8, 27, 7]\n",
      " Val: 1\n",
      " Te : 29\n",
      "8 [246, 248, 253, 252, 242, 245, 250, 251, 243, 254, 241, 247, 249, 244] 14\n",
      "27 [561, 564, 566, 565, 563, 567, 569, 568, 570, 562] 10\n",
      "7 [240, 225, 228, 236, 234, 239, 235, 230, 232, 233, 231, 229, 237, 238, 227, 226] 16\n",
      "1 [74, 73, 68, 66, 69, 62, 72, 67, 61, 71, 76, 64, 75, 65, 77, 60, 70, 63] 18\n",
      "29 [589, 588, 590, 582, 587, 586, 585, 584, 583, 581] 10\n",
      "Group 2 patients\n",
      " Tr: [5, 15, 24]\n",
      " Val: 19\n",
      " Te : 22\n",
      "5 [201, 208, 198, 199, 204, 205, 196, 206, 194, 195, 197, 207, 209, 200, 202, 203] 16\n",
      "15 [346, 343, 351, 350, 345, 349, 348, 352, 344, 347] 10\n",
      "24 [538, 532, 535, 536, 531, 537, 534, 541, 540, 539, 533] 11\n",
      "19 [388, 389, 387, 391, 384, 390, 392, 385, 383, 386] 10\n",
      "22 [473, 481, 474, 476, 475, 479, 472, 470, 480, 469, 478, 477, 483, 482, 471] 15\n",
      "Group 3 patients\n",
      " Tr: [13, 2, 16]\n",
      " Val: 17\n",
      " Te : 4\n",
      "13 [326, 329, 328, 331, 325, 332, 324, 327, 330, 323] 10\n",
      "2 [89, 98, 96, 83, 78, 79, 95, 90, 103, 112, 92, 108, 82, 91, 111, 80, 101, 106, 102, 84, 100, 93, 107, 97, 113, 109, 85, 81, 87, 94, 110, 86, 105, 99, 88, 104] 36\n",
      "16 [354, 355, 360, 353, 357, 361, 356, 358, 359, 362] 10\n",
      "17 [364, 363, 366, 372, 368, 370, 367, 365, 371, 369] 10\n",
      "4 [178, 169, 177, 170, 174, 192, 183, 165, 151, 182, 157, 155, 156, 154, 175, 181, 176, 161, 179, 162, 158, 189, 150, 167, 171, 153, 152, 159, 168, 173, 163, 193, 166, 164, 188, 191, 185, 186, 172, 180, 160, 187, 190, 184] 44\n"
     ]
    }
   ],
   "source": [
    "num_als=15\n",
    "num_ctrl = 5\n",
    "patient_idxs_finetune, patient_idxs_test = split_dataset(num_als, num_ctrl)\n",
    "patient_idxs = group_patients(patient_idxs_finetune)\n",
    "idx_tr, idx_val, idx_te = custom_split_finetuning(patient_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "governing-portfolio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples to train the finetune model :  255  -> ALS :  191 , CTRL :  64\n",
      "Number of samples to validate the finetune model :  48  -> ALS :  48 , CTRL :  0\n",
      "Number of samples to test the finetune model :  79  -> ALS :  54 , CTRL :  25\n"
     ]
    }
   ],
   "source": [
    "n1 = len([i for i in idx_tr if i < 393])\n",
    "n2 = len([i for i in idx_val if i < 393])\n",
    "n3 = len([i for i in idx_te if i < 393])\n",
    "print(\"Number of samples to train the finetune model : \", len(idx_tr), \" -> ALS : \", n1, \", CTRL : \", len(idx_tr)-n1)\n",
    "print(\"Number of samples to validate the finetune model : \", len(idx_val), \" -> ALS : \", n2, \", CTRL : \", len(idx_val)-n2)\n",
    "print(\"Number of samples to test the finetune model : \", len(idx_te), \" -> ALS : \", n3, \", CTRL : \", len(idx_te)-n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "confirmed-boulder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples to test :  209  -> ALS :  100 , CTRL :  109\n"
     ]
    }
   ],
   "source": [
    "fn_idx_te = get_test_indices(patient_idxs_test)\n",
    "m= len([i for i in fn_idx_te if i < 393])\n",
    "print(\"Number of samples to test : \", len(fn_idx_te), \" -> ALS : \", m, \", CTRL : \", len(fn_idx_te)-m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "early-hello",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 90.98\n",
      "  Val acc: 100.00\n",
      "  Test acc: 84.81\n",
      "Finished: 7.69s\n",
      "Accuracy: 40.2%\n",
      "2\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 87.06\n",
      "  Val acc: 100.00\n",
      "  Test acc: 89.87\n",
      "Finished: 7.51s\n",
      "Accuracy: 35.9%\n",
      "3\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 88.63\n",
      "  Val acc: 100.00\n",
      "  Test acc: 83.54\n",
      "Finished: 7.30s\n",
      "Accuracy: 42.1%\n",
      "4\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 88.63\n",
      "  Val acc: 100.00\n",
      "  Test acc: 86.08\n",
      "Finished: 7.29s\n",
      "Accuracy: 35.9%\n",
      "5\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 89.02\n",
      "  Val acc: 100.00\n",
      "  Test acc: 82.28\n",
      "Finished: 7.30s\n",
      "Accuracy: 40.7%\n",
      "6\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 87.84\n",
      "  Val acc: 100.00\n",
      "  Test acc: 86.08\n",
      "Finished: 7.32s\n",
      "Accuracy: 36.4%\n",
      "7\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 86.27\n",
      "  Val acc: 100.00\n",
      "  Test acc: 74.68\n",
      "Finished: 7.23s\n",
      "Accuracy: 48.8%\n",
      "8\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 89.02\n",
      "  Val acc: 97.92\n",
      "  Test acc: 93.67\n",
      "Finished: 7.21s\n",
      "Accuracy: 31.1%\n",
      "9\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 88.63\n",
      "  Val acc: 100.00\n",
      "  Test acc: 83.54\n",
      "Finished: 7.32s\n",
      "Accuracy: 38.8%\n",
      "10\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 89.41\n",
      "  Val acc: 100.00\n",
      "  Test acc: 98.73\n",
      "Finished: 7.44s\n",
      "Accuracy: 33.5%\n",
      "0.3832535885167464\n",
      "0.047387749186069854\n"
     ]
    }
   ],
   "source": [
    "list_acc = results(1, idx_tr, idx_val, idx_te, fn_idx_te)\n",
    "print(mean(list_acc))\n",
    "print(np.std(list_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-brain",
   "metadata": {},
   "source": [
    "The accuracy is corely correlated to the number of samples -> unbalanced data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-partner",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
