{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "touched-baseline",
   "metadata": {},
   "source": [
    "# Fine-tuning experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-center",
   "metadata": {},
   "source": [
    "Based on the two notebooks : https://github.com/csho33/bacteria-ID/blob/master/1_reference_finetuning.ipynb & https://github.com/csho33/bacteria-ID/blob/master/3_clinical_finetuning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "reduced-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "t00 = time()\n",
    "import numpy as np\n",
    "import os,sys,re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-zambia",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "literary-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load from directory\n",
    "os.chdir(os.getcwd())\n",
    "base_dir = 'Raman_Data/'\n",
    "als_dir = base_dir + 'ALS/'\n",
    "ctrl_dir = base_dir + 'CTRL/'\n",
    "\n",
    "base_dir2 = 'Bacteria_TL'\n",
    "sys.path.append(base_dir2)\n",
    "\n",
    "models = ['pretrained_model.ckpt', 'finetuned_model.ckpt', 'clinical_pretrained_model.ckpt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "possible-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_als = os.listdir(als_dir)\n",
    "all_files_als.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "\n",
    "all_files_ctrl = os.listdir(ctrl_dir)\n",
    "all_files_ctrl.sort(key=lambda f: int(re.sub('\\D', '', f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "hydraulic-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(file, dir):\n",
    "    with open(dir + file, 'rt') as fd:\n",
    "        data=[]\n",
    "        line = fd.readline()\n",
    "        nline = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", line)\n",
    "        data.append(nline)\n",
    "        while line:\n",
    "            line=fd.readline()\n",
    "            nline = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", line)\n",
    "            data.append(nline)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "peripheral-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[] #actual y of spectra\n",
    "Y=[] # 1 -> als; 0 -> ctrl\n",
    "coord=[] #actual x of spectra\n",
    "\n",
    "sep=[60,78,114,150,194,210,225,241,255,280,299,313,323,333,343,353,363,373,383,393] #Il manque le 227\n",
    "groups=[] #for GROUP K FOLD\n",
    "group=0\n",
    "index=1\n",
    "for f in all_files_als:\n",
    "    data=[]\n",
    "    datab=[]\n",
    "    for e in parse_text(f, als_dir):\n",
    "        if len(e) > 0:\n",
    "            datab.append(float(e[0]))\n",
    "            data.append(float(e[1]))\n",
    "    coord.append(datab)\n",
    "    X.append(data)\n",
    "    Y.append(1)\n",
    "    groups.append(group)\n",
    "    if index in sep:\n",
    "        group+=1\n",
    "    index+=1\n",
    "    \n",
    "sep=[33,76,91,138,149,158,168,178,188,198]\n",
    "index=1\n",
    "for f in all_files_ctrl:\n",
    "    data=[]\n",
    "    datab=[]\n",
    "    for e in parse_text(f, ctrl_dir):\n",
    "        if len(e) > 0:\n",
    "            datab.append(float(e[0]))\n",
    "            data.append(float(e[1]))\n",
    "    coord.append(datab)\n",
    "    X.append(data)\n",
    "    Y.append(0)\n",
    "    groups.append(group)\n",
    "    if index in sep:\n",
    "        group+=1\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ruled-answer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(591, 1174) (591,)\n"
     ]
    }
   ],
   "source": [
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "groups=np.array(groups)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "coordinate-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "    for j in range (len(X[i])):\n",
    "        if(X[i][j] < 0):\n",
    "            X[i][j] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-ratio",
   "metadata": {},
   "source": [
    "## Split our dataset into a finetunable set and a full test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-carpet",
   "metadata": {},
   "source": [
    "First, we decide to split our dataset into :\n",
    "1) a \"finetunable\" set for finetune the pretrained model on our data\n",
    "\n",
    "2) a \"full test\" set i.e the left over patients to test our resulting finetuned model\n",
    "\n",
    "The split ratio is 2/3 -> 20 patients for finetune (12 ALS & 8 CTRL) and 10 for test (8 ALS & 2 CTRL). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "baking-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(num_als, num_ctrl):\n",
    "    patient_idxs_finetune = []\n",
    "\n",
    "    x = list(range(0, 20))\n",
    "    patient_idxs_finetune = random.sample(x,num_als)\n",
    "    patient_idxs_test = [i for i in x if i not in patient_idxs_finetune]\n",
    "\n",
    "    x2 = list(range(20, 30))\n",
    "    patient_idxs_finetune += random.sample(x2,num_ctrl)\n",
    "    patient_idxs_test += [i for i in x2 if i not in patient_idxs_finetune]\n",
    "\n",
    "    #Shuffle to avoid implicit leakage (1 the firsts and 0 the lasts)\n",
    "    random.shuffle(patient_idxs_finetune)\n",
    "    random.shuffle(patient_idxs_test)\n",
    "    return patient_idxs_finetune, patient_idxs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "surprising-tunisia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 [15, 29, 9, 13, 6, 7, 2, 28, 10, 19, 12, 25, 1, 20, 22, 5, 24, 0, 27, 26]\n",
      "10 [14, 16, 21, 11, 23, 4, 17, 3, 8, 18]\n"
     ]
    }
   ],
   "source": [
    "#Some test to be sure\n",
    "patient_idxs_finetune, patient_idxs_test = split_dataset(12, 8)\n",
    "print(len(patient_idxs_finetune), patient_idxs_finetune)\n",
    "print(len(patient_idxs_test), patient_idxs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-trailer",
   "metadata": {},
   "source": [
    "## Load ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "suspended-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import ResNet\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "listed-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN parameters\n",
    "batch_size=10\n",
    "layers = 6\n",
    "hidden_size = 100\n",
    "block_size = 2\n",
    "hidden_sizes = [hidden_size] * layers\n",
    "num_blocks = [block_size] * layers\n",
    "input_dim = 1174\n",
    "in_channels = 64\n",
    "n_classes = 2 # instead of 30, we use the 2 empiric groupings\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '{}'.format(0)\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "necessary-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove last layers\n",
    "def removekey(d, listofkeys):\n",
    "    r = dict(d)\n",
    "    for key in listofkeys:\n",
    "        print('key: {} is removed'.format(key))\n",
    "        r.pop(key)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "assigned-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(n=0):\n",
    "    cnn = ResNet(hidden_sizes, num_blocks, input_dim=input_dim,\n",
    "                    in_channels=in_channels, n_classes=n_classes)\n",
    "    if cuda: cnn.cuda()\n",
    "\n",
    "    checkpoint = torch.load(base_dir2 + '/' + models[n], map_location=lambda storage, loc: storage)\n",
    "    mod_weights = removekey(checkpoint, ['linear.weight', 'linear.bias'])\n",
    "    cnn.load_state_dict(mod_weights, strict=False)\n",
    "    return cnn, mod_weights, checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-marking",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-cradle",
   "metadata": {},
   "source": [
    "### Custom Train/Val/Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-schema",
   "metadata": {},
   "source": [
    "Based on the \"clinical\" notebook we decide to implement a custom method of train/val/test split : the 20 patients are grouped into 4 sub-groups. The first 3 patients of each group are assigned to the training set, the 4th to the validation set and the 5th into the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "voluntary-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20 patients into 4 groups of 5 patients\n",
    "def group_patients(patient_idxs_finetune):\n",
    "    patient_idxs = []\n",
    "    x = patient_idxs_finetune\n",
    "    for i in range(4):\n",
    "        l = random.sample(x,5)\n",
    "        patient_idxs.append(l)\n",
    "        x = [i for i in x if i not in l]\n",
    "    return patient_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "subsequent-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_idxs = group_patients(patient_idxs_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "annoying-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample train/val/te spectra -> each group [train, train, train, val, test]\n",
    "def custom_split_finetuning(patient_idxs):\n",
    "    idx_tr, idx_val, idx_te = [], [], []\n",
    "    for group_idx, patient_list in enumerate(patient_idxs):\n",
    "        print('Group {} patients'.format(group_idx))\n",
    "        print(' Tr: {}'.format(patient_list[:3]))\n",
    "        print(' Val: {}'.format(patient_list[3]))\n",
    "        print(' Te : {}'.format(patient_list[4]))\n",
    "        for j, patient in enumerate(patient_list):\n",
    "            l= np.where(groups == patient)\n",
    "            start_idx = l[0][0]\n",
    "            end_idx = l[0][len(l[0])-1]\n",
    "            idx_range = list(range(start_idx, end_idx+1))\n",
    "            np.random.shuffle(idx_range) #-> do we shuffle ? \n",
    "            print(patient, idx_range, len(idx_range))\n",
    "            if j < 3:\n",
    "                idx_tr.extend(idx_range)\n",
    "            elif j ==3:\n",
    "                idx_val.extend(idx_range)\n",
    "            else:\n",
    "                idx_te.extend(idx_range)\n",
    "    return idx_tr, idx_val, idx_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fuzzy-candle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0 patients\n",
      " Tr: [29, 1, 10]\n",
      " Val: 27\n",
      " Te : 25\n",
      "29 [589, 582, 587, 585, 584, 588, 583, 581, 586, 590] 10\n",
      "1 [70, 60, 64, 77, 73, 71, 72, 62, 74, 63, 69, 76, 67, 68, 75, 65, 61, 66] 18\n",
      "10 [282, 294, 281, 293, 285, 291, 290, 298, 286, 289, 284, 287, 280, 296, 292, 288, 283, 297, 295] 19\n",
      "27 [568, 562, 561, 564, 566, 563, 569, 570, 567, 565] 10\n",
      "25 [545, 543, 544, 546, 549, 548, 550, 542, 547] 9\n",
      "Group 1 patients\n",
      " Tr: [9, 7, 28]\n",
      " Val: 22\n",
      " Te : 19\n",
      "9 [263, 261, 272, 275, 268, 262, 258, 266, 274, 273, 256, 276, 270, 257, 278, 259, 279, 260, 277, 269, 267, 265, 271, 264, 255] 25\n",
      "7 [229, 236, 234, 238, 237, 233, 239, 228, 227, 240, 230, 225, 231, 232, 235, 226] 16\n",
      "28 [572, 575, 571, 573, 574, 577, 579, 578, 580, 576] 10\n",
      "22 [482, 474, 479, 480, 473, 476, 470, 477, 481, 478, 471, 469, 483, 475, 472] 15\n",
      "19 [391, 392, 383, 390, 388, 387, 384, 385, 386, 389] 10\n",
      "Group 2 patients\n",
      " Tr: [12, 6, 13]\n",
      " Val: 20\n",
      " Te : 15\n",
      "12 [316, 319, 315, 321, 318, 317, 320, 322, 313, 314] 10\n",
      "6 [224, 215, 218, 212, 214, 210, 220, 219, 221, 217, 222, 213, 211, 223, 216] 15\n",
      "13 [331, 329, 326, 332, 324, 328, 325, 327, 330, 323] 10\n",
      "20 [423, 422, 413, 398, 393, 408, 405, 425, 404, 418, 399, 400, 409, 397, 417, 396, 394, 402, 416, 403, 410, 395, 411, 407, 414, 406, 415, 421, 424, 412, 420, 401, 419] 33\n",
      "15 [348, 349, 345, 347, 350, 351, 343, 344, 346, 352] 10\n",
      "Group 3 patients\n",
      " Tr: [2, 26, 24]\n",
      " Val: 0\n",
      " Te : 5\n",
      "2 [105, 101, 110, 96, 79, 109, 78, 91, 81, 99, 93, 89, 80, 95, 106, 83, 88, 104, 92, 100, 94, 90, 85, 107, 108, 103, 86, 111, 98, 102, 112, 84, 82, 113, 87, 97] 36\n",
      "26 [560, 557, 551, 553, 555, 559, 558, 552, 556, 554] 10\n",
      "24 [538, 540, 537, 536, 532, 533, 541, 531, 539, 534, 535] 11\n",
      "0 [47, 46, 34, 23, 29, 28, 18, 42, 5, 15, 12, 44, 19, 1, 58, 27, 30, 3, 48, 51, 33, 4, 24, 6, 17, 50, 22, 0, 2, 8, 35, 57, 40, 43, 21, 9, 41, 13, 7, 14, 26, 32, 56, 31, 49, 36, 54, 59, 16, 53, 55, 39, 11, 38, 45, 20, 52, 10, 25, 37] 60\n",
      "5 [201, 205, 206, 194, 198, 195, 202, 200, 208, 204, 203, 199, 197, 196, 207, 209] 16\n",
      "190\n",
      "118\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "#Outputs len\n",
    "idx_tr, idx_val, idx_te = custom_split_finetuning(patient_idxs)\n",
    "print(len(idx_tr))\n",
    "print(len(idx_val))\n",
    "print(len(idx_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-station",
   "metadata": {},
   "source": [
    "## Finetuning based on custom split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "simple-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import spectral_dataloader\n",
    "from training import run_epoch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-alexander",
   "metadata": {},
   "source": [
    "Finetune the cnn model with the train, val, test index splitted earlier on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "average-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune CNN\n",
    "def finetune(cnn, idx_tr, idx_val, idx_te):\n",
    "    epochs = 1\n",
    "    batch_size = 10\n",
    "    t0 = time()\n",
    "    # Set up Adam optimizer\n",
    "    optimizer = optim.Adam(cnn.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
    "    # Set up dataloaders\n",
    "    dl_tr = spectral_dataloader(X, Y, idxs=idx_tr,\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "    dl_val = spectral_dataloader(X, Y, idxs=idx_val,\n",
    "        batch_size=batch_size, shuffle=False)\n",
    "    dl_te = spectral_dataloader(X, Y, idxs=idx_te,\n",
    "        batch_size=batch_size, shuffle=False)\n",
    "    # Fine-tune CNN for first fold\n",
    "    best_val = 0\n",
    "    no_improvement = 0\n",
    "    max_no_improvement = 5\n",
    "    print('Starting fine-tuning!')\n",
    "    for epoch in range(epochs):\n",
    "        print(' Epoch {}: {:0.2f}s'.format(epoch+1, time()-t0))\n",
    "        # Train\n",
    "        acc_tr, loss_tr = run_epoch(epoch, cnn, dl_tr, cuda,\n",
    "            training=True, optimizer=optimizer)\n",
    "        print('  Train acc: {:0.2f}'.format(acc_tr))\n",
    "        # Val\n",
    "        acc_val, loss_val = run_epoch(epoch, cnn, dl_val, cuda,\n",
    "            training=False, optimizer=optimizer)\n",
    "        print('  Val acc: {:0.2f}'.format(acc_val))\n",
    "        # Test\n",
    "        acc_te, loss_te = run_epoch(epoch, cnn, dl_te, cuda,\n",
    "            training=False, optimizer=optimizer)\n",
    "        print('  Test acc: {:0.2f}'.format(acc_te))\n",
    "        # Check performance for early stopping\n",
    "        if acc_val > best_val or epoch == 0:\n",
    "            best_val = acc_val\n",
    "            no_improvement = 0\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "        if no_improvement >= max_no_improvement:\n",
    "            print('Finished after {} epochs!'.format(epoch+1))\n",
    "            break\n",
    "    print('Finished: {:0.2f}s'.format(time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-jewel",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "equivalent-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import get_predictions\n",
    "from scipy import stats\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-jacob",
   "metadata": {},
   "source": [
    "Get the test indices for testing the model based on the patient IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "chemical-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1/ Getting test indices\n",
    "def get_test_indices(patient_idxs_test):\n",
    "    idx_te = []\n",
    "    for group_idx in patient_idxs_test:\n",
    "        l= np.where(groups == group_idx)\n",
    "        start_idx = l[0][0]\n",
    "        end_idx = l[0][len(l[0])-1]\n",
    "        idx_te += list(range(start_idx, end_idx+1))\n",
    "    return idx_te"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-fiction",
   "metadata": {},
   "source": [
    "Predict on cnn with index test resulting from the method above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "sensitive-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(cnn, idx_te):\n",
    "    #1/ Predicting on finetuned model\n",
    "    dl_te = spectral_dataloader(X, Y, idxs=idx_te,\n",
    "        batch_size=batch_size, shuffle=False)\n",
    "    #t0 = time()\n",
    "    y_hat = get_predictions(cnn, dl_te, cuda)\n",
    "    #print('Finished: {:0.2f}s'.format(time()-t0))\n",
    "    #2/ Getting the right Y indices for comparing\n",
    "    Y_l = []\n",
    "    for i in range(len(Y)):\n",
    "        if i in idx_te:\n",
    "            Y_l.append(Y[i])\n",
    "    #3/ Computing accuracy and std\n",
    "    acc = (y_hat == Y_l).mean()\n",
    "    print('Accuracy: {:0.1f}%'.format(100*acc))\n",
    "    return acc, Y_l, y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-people",
   "metadata": {},
   "source": [
    "## Get average accuracy and std on finetuned models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-anchor",
   "metadata": {},
   "source": [
    "Combine functions to have the average accuracy on 10 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "activated-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(num_model, idx_tr, idx_val, idx_te, fn_idx_te):\n",
    "    list_acc=[]\n",
    "    #Average on 10 times\n",
    "    for i in range(10):\n",
    "        print(i+1)\n",
    "        #Load model\n",
    "        cnn, _, _ = load_model(num_model)\n",
    "        #finetune it owith custom split\n",
    "        finetune(cnn, idx_tr, idx_val, idx_te)\n",
    "        #get accuracy to make an average and std on test set\n",
    "        list_acc.append(predict(cnn, fn_idx_te)[0])\n",
    "    return list_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-polyester",
   "metadata": {},
   "source": [
    "## Trials :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-difference",
   "metadata": {},
   "source": [
    "Distribution of 12 ALS & 8 CTRL :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "selective-publication",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0 patients\n",
      " Tr: [19, 2, 26]\n",
      " Val: 23\n",
      " Te : 24\n",
      "19 [389, 391, 390, 385, 392, 386, 383, 388, 384, 387] 10\n",
      "2 [88, 110, 83, 97, 96, 90, 111, 91, 104, 99, 92, 105, 86, 85, 98, 102, 103, 109, 87, 81, 79, 100, 82, 113, 112, 93, 80, 95, 106, 89, 84, 101, 107, 78, 94, 108] 36\n",
      "26 [557, 558, 553, 551, 559, 560, 556, 552, 554, 555] 10\n",
      "23 [524, 486, 517, 487, 529, 488, 502, 507, 503, 508, 500, 515, 528, 504, 493, 525, 489, 514, 510, 526, 499, 492, 501, 522, 491, 497, 484, 519, 505, 530, 511, 516, 496, 520, 521, 513, 523, 518, 506, 490, 485, 495, 494, 498, 509, 527, 512] 47\n",
      "24 [540, 537, 535, 536, 539, 541, 534, 533, 532, 538, 531] 11\n",
      "Group 1 patients\n",
      " Tr: [11, 12, 16]\n",
      " Val: 15\n",
      " Te : 10\n",
      "11 [308, 304, 305, 303, 299, 307, 302, 310, 301, 312, 309, 311, 306, 300] 14\n",
      "12 [321, 317, 320, 316, 322, 318, 314, 313, 315, 319] 10\n",
      "16 [355, 354, 353, 359, 361, 362, 356, 358, 360, 357] 10\n",
      "15 [347, 350, 351, 343, 346, 344, 348, 352, 349, 345] 10\n",
      "10 [282, 284, 296, 285, 280, 294, 298, 287, 297, 283, 291, 286, 289, 295, 290, 288, 293, 292, 281] 19\n",
      "Group 2 patients\n",
      " Tr: [7, 3, 21]\n",
      " Val: 14\n",
      " Te : 25\n",
      "7 [225, 226, 231, 239, 238, 237, 232, 228, 236, 235, 227, 229, 240, 230, 234, 233] 16\n",
      "3 [141, 145, 131, 142, 117, 149, 134, 147, 129, 130, 114, 139, 122, 146, 123, 126, 115, 125, 120, 135, 144, 127, 128, 148, 124, 136, 121, 116, 143, 137, 132, 140, 118, 138, 119, 133] 36\n",
      "21 [466, 461, 436, 455, 440, 459, 441, 463, 450, 431, 443, 445, 437, 464, 456, 458, 430, 448, 442, 434, 460, 447, 435, 438, 451, 446, 433, 462, 468, 453, 432, 457, 454, 465, 449, 428, 444, 439, 452, 426, 429, 427, 467] 43\n",
      "14 [339, 337, 338, 335, 336, 334, 341, 333, 342, 340] 10\n",
      "25 [546, 544, 547, 549, 548, 550, 545, 542, 543] 9\n",
      "Group 3 patients\n",
      " Tr: [6, 28, 22]\n",
      " Val: 29\n",
      " Te : 8\n",
      "6 [217, 218, 224, 212, 219, 223, 210, 213, 221, 215, 222, 211, 214, 216, 220] 15\n",
      "28 [578, 580, 573, 571, 577, 579, 575, 574, 576, 572] 10\n",
      "22 [476, 473, 477, 483, 472, 479, 470, 475, 482, 481, 478, 480, 469, 471, 474] 15\n",
      "29 [585, 583, 586, 590, 587, 589, 581, 582, 584, 588] 10\n",
      "8 [254, 246, 248, 244, 245, 241, 252, 251, 253, 249, 250, 242, 243, 247] 14\n"
     ]
    }
   ],
   "source": [
    "num_als=12\n",
    "num_ctrl = 8\n",
    "patient_idxs_finetune, patient_idxs_test = split_dataset(num_als, num_ctrl)\n",
    "patient_idxs = group_patients(patient_idxs_finetune)\n",
    "idx_tr, idx_val, idx_te = custom_split_finetuning(patient_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "liberal-fountain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples to train the finetune model :  225  -> ALS :  147 , CTRL :  78\n",
      "Number of samples to validate the finetune model :  77  -> ALS :  20 , CTRL :  57\n",
      "Number of samples to test the finetune model :  53  -> ALS :  33 , CTRL :  20\n"
     ]
    }
   ],
   "source": [
    "n1 = len([i for i in idx_tr if i < 393])\n",
    "n2 = len([i for i in idx_val if i < 393])\n",
    "n3 = len([i for i in idx_te if i < 393])\n",
    "print(\"Number of samples to train the finetune model : \", len(idx_tr), \" -> ALS : \", n1, \", CTRL : \", len(idx_tr)-n1)\n",
    "print(\"Number of samples to validate the finetune model : \", len(idx_val), \" -> ALS : \", n2, \", CTRL : \", len(idx_val)-n2)\n",
    "print(\"Number of samples to test the finetune model : \", len(idx_te), \" -> ALS : \", n3, \", CTRL : \", len(idx_te)-n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "sixth-defensive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples to test :  236  -> ALS :  193 , CTRL :  43\n"
     ]
    }
   ],
   "source": [
    "fn_idx_te = get_test_indices(patient_idxs_test)\n",
    "m= len([i for i in fn_idx_te if i < 393])\n",
    "print(\"Number of samples to test : \", len(fn_idx_te), \" -> ALS : \", m, \", CTRL : \", len(fn_idx_te)-m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-train",
   "metadata": {},
   "source": [
    "- pretrained_model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "minor-privacy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 86.67\n",
      "  Val acc: 45.45\n",
      "  Test acc: 77.36\n",
      "Finished: 7.28s\n",
      "Accuracy: 81.4%\n",
      "2\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 82.22\n",
      "  Val acc: 92.21\n",
      "  Test acc: 79.25\n",
      "Finished: 7.10s\n",
      "Accuracy: 66.5%\n",
      "3\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 86.67\n",
      "  Val acc: 88.31\n",
      "  Test acc: 79.25\n",
      "Finished: 7.05s\n",
      "Accuracy: 74.2%\n",
      "4\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 84.44\n",
      "  Val acc: 81.82\n",
      "  Test acc: 77.36\n",
      "Finished: 7.08s\n",
      "Accuracy: 78.4%\n",
      "5\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 88.44\n",
      "  Val acc: 89.61\n",
      "  Test acc: 79.25\n",
      "Finished: 7.12s\n",
      "Accuracy: 72.0%\n",
      "6\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 87.11\n",
      "  Val acc: 83.12\n",
      "  Test acc: 81.13\n",
      "Finished: 7.06s\n",
      "Accuracy: 78.4%\n",
      "7\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 83.56\n",
      "  Val acc: 90.91\n",
      "  Test acc: 79.25\n",
      "Finished: 7.21s\n",
      "Accuracy: 72.9%\n",
      "8\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 83.11\n",
      "  Val acc: 96.10\n",
      "  Test acc: 79.25\n",
      "Finished: 7.10s\n",
      "Accuracy: 70.3%\n",
      "9\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 91.11\n",
      "  Val acc: 93.51\n",
      "  Test acc: 81.13\n",
      "Finished: 7.05s\n",
      "Accuracy: 70.3%\n",
      "10\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 86.22\n",
      "  Val acc: 80.52\n",
      "  Test acc: 81.13\n",
      "Finished: 7.11s\n",
      "Accuracy: 75.8%\n",
      "0.7402542372881356\n",
      "0.04288043477271473\n"
     ]
    }
   ],
   "source": [
    "list_acc = results(0, idx_tr, idx_val, idx_te, fn_idx_te)\n",
    "print(mean(list_acc))\n",
    "print(np.std(list_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-inclusion",
   "metadata": {},
   "source": [
    "- finetuned_model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "indirect-samoa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 85.33\n",
      "  Val acc: 97.40\n",
      "  Test acc: 79.25\n",
      "Finished: 7.08s\n",
      "Accuracy: 66.1%\n",
      "2\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 86.67\n",
      "  Val acc: 44.16\n",
      "  Test acc: 75.47\n",
      "Finished: 7.24s\n",
      "Accuracy: 80.5%\n",
      "3\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 89.33\n",
      "  Val acc: 90.91\n",
      "  Test acc: 77.36\n",
      "Finished: 7.12s\n",
      "Accuracy: 75.8%\n",
      "4\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 84.89\n",
      "  Val acc: 97.40\n",
      "  Test acc: 75.47\n",
      "Finished: 7.05s\n",
      "Accuracy: 66.1%\n",
      "5\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 87.56\n",
      "  Val acc: 93.51\n",
      "  Test acc: 79.25\n",
      "Finished: 7.09s\n",
      "Accuracy: 71.6%\n",
      "6\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 89.33\n",
      "  Val acc: 94.81\n",
      "  Test acc: 79.25\n",
      "Finished: 7.07s\n",
      "Accuracy: 68.2%\n",
      "7\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 84.00\n",
      "  Val acc: 90.91\n",
      "  Test acc: 79.25\n",
      "Finished: 7.08s\n",
      "Accuracy: 72.5%\n",
      "8\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 84.44\n",
      "  Val acc: 81.82\n",
      "  Test acc: 77.36\n",
      "Finished: 7.12s\n",
      "Accuracy: 75.8%\n",
      "9\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 85.78\n",
      "  Val acc: 93.51\n",
      "  Test acc: 75.47\n",
      "Finished: 7.07s\n",
      "Accuracy: 68.6%\n",
      "10\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 86.22\n",
      "  Val acc: 96.10\n",
      "  Test acc: 79.25\n",
      "Finished: 7.18s\n",
      "Accuracy: 70.3%\n",
      "0.7156779661016949\n",
      "0.04453992524812852\n"
     ]
    }
   ],
   "source": [
    "list_acc = results(1, idx_tr, idx_val, idx_te, fn_idx_te)\n",
    "print(mean(list_acc))\n",
    "print(np.std(list_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-anthropology",
   "metadata": {},
   "source": [
    "- clinical_pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "impressive-spending",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 88.00\n",
      "  Val acc: 90.91\n",
      "  Test acc: 81.13\n",
      "Finished: 7.11s\n",
      "Accuracy: 70.3%\n",
      "2\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 88.00\n",
      "  Val acc: 96.10\n",
      "  Test acc: 81.13\n",
      "Finished: 7.04s\n",
      "Accuracy: 67.8%\n",
      "3\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 86.22\n",
      "  Val acc: 94.81\n",
      "  Test acc: 81.13\n",
      "Finished: 7.10s\n",
      "Accuracy: 67.4%\n",
      "4\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 85.78\n",
      "  Val acc: 94.81\n",
      "  Test acc: 81.13\n",
      "Finished: 7.09s\n",
      "Accuracy: 66.5%\n",
      "5\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 86.22\n",
      "  Val acc: 84.42\n",
      "  Test acc: 81.13\n",
      "Finished: 7.09s\n",
      "Accuracy: 71.6%\n",
      "6\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 80.44\n",
      "  Val acc: 63.64\n",
      "  Test acc: 81.13\n",
      "Finished: 7.05s\n",
      "Accuracy: 78.8%\n",
      "7\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 87.56\n",
      "  Val acc: 94.81\n",
      "  Test acc: 81.13\n",
      "Finished: 7.06s\n",
      "Accuracy: 67.8%\n",
      "8\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 90.22\n",
      "  Val acc: 92.21\n",
      "  Test acc: 81.13\n",
      "Finished: 7.09s\n",
      "Accuracy: 66.9%\n",
      "9\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 85.78\n",
      "  Val acc: 87.01\n",
      "  Test acc: 81.13\n",
      "Finished: 7.04s\n",
      "Accuracy: 70.8%\n",
      "10\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 83.11\n",
      "  Val acc: 92.21\n",
      "  Test acc: 81.13\n",
      "Finished: 7.09s\n",
      "Accuracy: 66.9%\n",
      "0.6949152542372882\n",
      "0.03545169603957948\n"
     ]
    }
   ],
   "source": [
    "list_acc = results(2, idx_tr, idx_val, idx_te, fn_idx_te)\n",
    "print(mean(list_acc))\n",
    "print(np.std(list_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-notebook",
   "metadata": {},
   "source": [
    "Distribution of 15 ALS & 5 CTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "becoming-replication",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0 patients\n",
      " Tr: [13, 0, 22]\n",
      " Val: 1\n",
      " Te : 12\n",
      "13 [325, 324, 326, 332, 323, 329, 328, 327, 331, 330] 10\n",
      "0 [35, 57, 28, 19, 31, 22, 34, 48, 15, 6, 41, 20, 7, 36, 58, 12, 16, 32, 53, 0, 27, 46, 17, 13, 45, 21, 26, 43, 44, 4, 23, 39, 14, 56, 47, 37, 5, 49, 9, 51, 11, 55, 59, 40, 50, 1, 54, 25, 38, 10, 2, 18, 33, 52, 3, 29, 42, 24, 8, 30] 60\n",
      "22 [470, 471, 475, 479, 476, 473, 474, 478, 477, 481, 469, 483, 472, 480, 482] 15\n",
      "1 [73, 69, 67, 60, 75, 71, 62, 76, 64, 74, 63, 68, 77, 66, 72, 61, 70, 65] 18\n",
      "12 [322, 321, 314, 316, 319, 318, 320, 315, 313, 317] 10\n",
      "Group 1 patients\n",
      " Tr: [28, 29, 10]\n",
      " Val: 11\n",
      " Te : 26\n",
      "28 [577, 574, 576, 578, 572, 580, 579, 573, 571, 575] 10\n",
      "29 [583, 588, 584, 585, 586, 587, 582, 590, 589, 581] 10\n",
      "10 [293, 292, 289, 281, 297, 295, 286, 285, 291, 282, 296, 283, 287, 294, 284, 290, 280, 288, 298] 19\n",
      "11 [312, 300, 303, 305, 309, 301, 308, 299, 306, 302, 307, 310, 304, 311] 14\n",
      "26 [559, 556, 558, 551, 555, 552, 553, 557, 560, 554] 10\n",
      "Group 2 patients\n",
      " Tr: [14, 8, 7]\n",
      " Val: 5\n",
      " Te : 17\n",
      "14 [334, 341, 338, 339, 340, 333, 342, 337, 335, 336] 10\n",
      "8 [248, 253, 247, 244, 254, 242, 252, 245, 241, 250, 243, 249, 246, 251] 14\n",
      "7 [227, 236, 239, 230, 231, 240, 238, 237, 225, 235, 234, 229, 226, 228, 233, 232] 16\n",
      "5 [203, 207, 194, 195, 199, 198, 208, 197, 204, 200, 201, 205, 209, 202, 206, 196] 16\n",
      "17 [367, 372, 366, 363, 370, 365, 368, 364, 369, 371] 10\n",
      "Group 3 patients\n",
      " Tr: [16, 15, 19]\n",
      " Val: 9\n",
      " Te : 25\n",
      "16 [362, 361, 359, 354, 355, 360, 353, 356, 358, 357] 10\n",
      "15 [344, 343, 345, 346, 348, 347, 349, 351, 350, 352] 10\n",
      "19 [388, 385, 386, 387, 383, 390, 389, 392, 384, 391] 10\n",
      "9 [279, 267, 262, 266, 278, 265, 274, 271, 273, 255, 272, 261, 259, 268, 256, 275, 260, 258, 277, 276, 269, 264, 257, 270, 263] 25\n",
      "25 [547, 544, 546, 548, 542, 543, 545, 549, 550] 9\n"
     ]
    }
   ],
   "source": [
    "num_als=15\n",
    "num_ctrl = 5\n",
    "patient_idxs_finetune, patient_idxs_test = split_dataset(num_als, num_ctrl)\n",
    "patient_idxs = group_patients(patient_idxs_finetune)\n",
    "idx_tr, idx_val, idx_te = custom_split_finetuning(patient_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "western-judgment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples to train the finetune model :  194  -> ALS :  159 , CTRL :  35\n",
      "Number of samples to validate the finetune model :  73  -> ALS :  73 , CTRL :  0\n",
      "Number of samples to test the finetune model :  39  -> ALS :  20 , CTRL :  19\n"
     ]
    }
   ],
   "source": [
    "n1 = len([i for i in idx_tr if i < 393])\n",
    "n2 = len([i for i in idx_val if i < 393])\n",
    "n3 = len([i for i in idx_te if i < 393])\n",
    "print(\"Number of samples to train the finetune model : \", len(idx_tr), \" -> ALS : \", n1, \", CTRL : \", len(idx_tr)-n1)\n",
    "print(\"Number of samples to validate the finetune model : \", len(idx_val), \" -> ALS : \", n2, \", CTRL : \", len(idx_val)-n2)\n",
    "print(\"Number of samples to test the finetune model : \", len(idx_te), \" -> ALS : \", n3, \", CTRL : \", len(idx_te)-n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "concrete-pontiac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples to test :  195  -> ALS :  76 , CTRL :  119\n"
     ]
    }
   ],
   "source": [
    "fn_idx_te = get_test_indices(patient_idxs_test)\n",
    "m= len([i for i in fn_idx_te if i < 393])\n",
    "print(\"Number of samples to test : \", len(fn_idx_te), \" -> ALS : \", m, \", CTRL : \", len(fn_idx_te)-m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "exterior-midnight",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 88.80\n",
      "  Val acc: 79.17\n",
      "  Test acc: 41.89\n",
      "Finished: 7.34s\n",
      "Accuracy: 39.0%\n",
      "2\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 92.00\n",
      "  Val acc: 79.17\n",
      "  Test acc: 43.24\n",
      "Finished: 7.15s\n",
      "Accuracy: 39.0%\n",
      "3\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 91.20\n",
      "  Val acc: 81.94\n",
      "  Test acc: 48.65\n",
      "Finished: 7.21s\n",
      "Accuracy: 45.1%\n",
      "4\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 92.80\n",
      "  Val acc: 79.17\n",
      "  Test acc: 41.89\n",
      "Finished: 7.36s\n",
      "Accuracy: 39.5%\n",
      "5\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 89.20\n",
      "  Val acc: 79.17\n",
      "  Test acc: 52.70\n",
      "Finished: 7.12s\n",
      "Accuracy: 42.1%\n",
      "6\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 92.00\n",
      "  Val acc: 79.17\n",
      "  Test acc: 52.70\n",
      "Finished: 7.21s\n",
      "Accuracy: 41.5%\n",
      "7\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 90.80\n",
      "  Val acc: 80.56\n",
      "  Test acc: 52.70\n",
      "Finished: 7.20s\n",
      "Accuracy: 45.6%\n",
      "8\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 88.00\n",
      "  Val acc: 79.17\n",
      "  Test acc: 41.89\n",
      "Finished: 7.21s\n",
      "Accuracy: 39.0%\n",
      "9\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 92.40\n",
      "  Val acc: 79.17\n",
      "  Test acc: 48.65\n",
      "Finished: 7.27s\n",
      "Accuracy: 41.0%\n",
      "10\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 90.40\n",
      "  Val acc: 79.17\n",
      "  Test acc: 41.89\n",
      "Finished: 7.21s\n",
      "Accuracy: 39.0%\n",
      "0.4107692307692308\n",
      "0.024211428993052054\n"
     ]
    }
   ],
   "source": [
    "list_acc = results(1, idx_tr, idx_val, idx_te, fn_idx_te)\n",
    "print(mean(list_acc))\n",
    "print(np.std(list_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-observer",
   "metadata": {},
   "source": [
    "## Plot confusion matrix of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "variable-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "expressed-porter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0 patients\n",
      " Tr: [13, 4, 9]\n",
      " Val: 7\n",
      " Te : 26\n",
      "13 [328, 323, 329, 327, 331, 330, 325, 326, 324, 332] 10\n",
      "4 [176, 154, 169, 156, 157, 163, 170, 160, 177, 174, 162, 173, 178, 166, 168, 187, 164, 161, 184, 152, 181, 172, 175, 180, 189, 186, 153, 193, 185, 167, 179, 182, 155, 151, 171, 159, 192, 191, 183, 188, 150, 190, 158, 165] 44\n",
      "9 [266, 278, 273, 262, 255, 276, 267, 264, 257, 263, 275, 259, 268, 261, 272, 260, 258, 270, 271, 269, 274, 256, 265, 279, 277] 25\n",
      "7 [230, 231, 226, 232, 238, 234, 233, 240, 239, 225, 236, 229, 227, 237, 228, 235] 16\n",
      "26 [553, 551, 558, 555, 557, 560, 556, 559, 552, 554] 10\n",
      "Group 1 patients\n",
      " Tr: [22, 1, 21]\n",
      " Val: 8\n",
      " Te : 25\n",
      "22 [474, 477, 472, 470, 482, 471, 480, 483, 479, 475, 481, 469, 478, 473, 476] 15\n",
      "1 [70, 75, 63, 77, 62, 66, 68, 67, 61, 65, 64, 76, 72, 73, 60, 71, 69, 74] 18\n",
      "21 [457, 460, 454, 452, 434, 443, 467, 438, 461, 462, 456, 463, 442, 446, 433, 432, 447, 468, 428, 440, 427, 458, 466, 444, 459, 464, 426, 445, 439, 453, 431, 449, 441, 451, 448, 437, 455, 429, 436, 435, 430, 465, 450] 43\n",
      "8 [247, 251, 254, 242, 252, 249, 243, 244, 250, 248, 246, 253, 241, 245] 14\n",
      "25 [542, 543, 546, 550, 544, 549, 545, 547, 548] 9\n",
      "Group 2 patients\n",
      " Tr: [2, 24, 11]\n",
      " Val: 10\n",
      " Te : 20\n",
      "2 [96, 101, 103, 87, 79, 91, 84, 81, 82, 106, 78, 112, 97, 104, 111, 105, 109, 93, 113, 89, 110, 90, 92, 100, 86, 107, 83, 80, 94, 85, 95, 98, 99, 102, 108, 88] 36\n",
      "24 [533, 532, 541, 537, 536, 540, 538, 535, 534, 539, 531] 11\n",
      "11 [300, 303, 311, 307, 308, 299, 305, 306, 310, 302, 312, 304, 309, 301] 14\n",
      "10 [288, 290, 289, 296, 292, 285, 297, 283, 291, 280, 287, 298, 281, 293, 282, 295, 286, 294, 284] 19\n",
      "20 [401, 404, 416, 423, 424, 402, 420, 419, 418, 413, 414, 409, 395, 407, 411, 397, 412, 399, 400, 408, 393, 417, 415, 394, 405, 398, 396, 410, 421, 406, 425, 422, 403] 33\n",
      "Group 3 patients\n",
      " Tr: [5, 19, 17]\n",
      " Val: 27\n",
      " Te : 14\n",
      "5 [202, 205, 206, 198, 199, 197, 201, 200, 209, 208, 194, 196, 204, 195, 207, 203] 16\n",
      "19 [386, 385, 392, 391, 390, 383, 389, 387, 388, 384] 10\n",
      "17 [366, 370, 365, 367, 368, 364, 369, 363, 371, 372] 10\n",
      "27 [570, 563, 569, 566, 565, 564, 561, 562, 567, 568] 10\n",
      "14 [342, 335, 333, 334, 341, 338, 336, 339, 340, 337] 10\n",
      "key: linear.weight is removed\n",
      "key: linear.bias is removed\n",
      "Starting fine-tuning!\n",
      " Epoch 1: 0.00s\n",
      "  Train acc: 92.46\n",
      "  Val acc: 83.05\n",
      "  Test acc: 54.84\n",
      "Finished: 7.38s\n",
      "Accuracy: 72.8%\n"
     ]
    }
   ],
   "source": [
    "num_als=13\n",
    "num_ctrl = 7\n",
    "patient_idxs_finetune, patient_idxs_test = split_dataset(num_als, num_ctrl)\n",
    "patient_idxs = group_patients(patient_idxs_finetune)\n",
    "idx_tr, idx_val, idx_te = custom_split_finetuning(patient_idxs)#Load model\n",
    "cnn, _, _ = load_model(1)\n",
    "#finetune it owith custom split\n",
    "finetune(cnn, idx_tr, idx_val, idx_te)\n",
    "acc, y, y_hat = predict(cnn, fn_idx_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "steady-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAH4CAYAAADgnlzVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAm+0lEQVR4nO3deZgdVZn48e/bYYugBCKoBBhwEFBBZfOHexAQUYgLIjKMirgruCIoruAGzIwwgAq4odFBQDEKgQQYBhAhaBQwAWTHsG8hQCAESN7fH/cGOs3tvp1O17k3t74fn3pu+tS5VW/5hLz9njqnKjITSZJUrb5OByBJUh2YcCVJKsCEK0lSASZcSZIKMOFKklSACVeSpAJMuJIkFWDCramIWCMiXtLpOCSpLky49bULMKvTQUhSXZhwJUkqwIQrSVIBJlxJkgow4UqSVMBKnQ5AoysiJg2z63aVBiJJWkr4er7eEhGLgQRiGN0zM8dUHJIkCSvcXrRDpwOQJD2TFa4kSQU4aarGImLvTscgSXVhwq2hiHh3RFwF/LLTsUhSXZhwe1BEHBIRt0TEoxFxeUS8udm+fURcDpwMrAV8sqOBSlKNmHB7TER8CvgW8Bwaz0peF5gSER8GLgI2Ab4GbJKZx3csUGkIETEhIl7Xov11ETEjIuZHxHURsW8HwpNGxElTPSYirgAeAHbPzPkR0QccA3wcuBbYJTNv7WCIUlsR8WPgFZm5bb+2jYDZwGrAlcAGwHhgt8w8uxNxSsvCCrf3vAg4OjPnA2TmYuC7NNblfsNkqxXE9sCpA9oOAMYC78rMbYCNgZnApwrHJo2ICbf3jAXuHNB2V/PzpsKxSCO1HnD1gLY3A9dk5hSAzHwE+D6wTdnQpJEx4famwe4TLCoahTRyqwLzl/wQEWsCmwMXDuh3M7BmwbikEfNJU71pckQ82qL9fyJiQb+fszk0J3WbOcCWwAXNn19L47bIJQP6rQHMKxaVtBxMuL3nIlpXuAMrA6mbnQkcFBEzgbuBLwMLgekD+m0H/LNwbNKIOEtZUteJiPHAn4GNljQBh2Tm4QP6/QM4IzO/UDZCadmZcHtMRPwU+GZm3tzpWKTlERFrAHsCawMzMvNPA/avC7wXODMzr+1AiNIyMeH2mObr+bbPzD93OhapahHxPGCbzDyr07FI7ThLWdKK7LXAGZ0OQhoOE64kSQU4S7k3vSUiNh9Ox8z8RdXBSJK8h9tzmvdwk8asznYyM8dUHJJUmYjYAzjVv8daEVjh9qb30XjIuySpS5hwe9P1mXllp4OQRqr5msnheHmlgUijyIQrqRsdvQx9vS+mFYIJV1I32ngZ+q5aWRTSKHLSVI+JiO/ReHvKyZl53iB9dgJ2Bb7WfMWZtMKJiFcA+wF7Z+Y6HQ5Hast1uL3nHhrvDR34VpX+LgH2Aj5WJCJplETEWhGxf0T8DfgrsD8wq8NhScNiwu09bwNOzMxWr+cDoLnvBGCPYlFJyyEi3hQRvwbuAI6hMVnqJGDTzHxjJ2OThsuE23teAlw6jH4zmn2lrhQRG0fEYRHxT+Bs4J3ANBrL3gL4eWbe0MkYpWXhpKnesyrw2DD6LQRWqzgWaUQi4nzg9TQS69XAF4DJmXlvRKzZ0eCkETLh9p67gM1ovIh+KJvReLG31I0m0ljucwZwQGbe2tlwpOXnkHLvuQj4WEQM+qi75r6PAheUCkpaRl8BbgAmATdHxPSIeE9EuARIKywTbu85CngZcFrzXaFLabad2uxzVOHYpGHJzO9k5mY0Kt1fAq8GfkVjBOcYGtWvaxq1QnEdbg+KiI8BxwGLgJnALc1d/wJsS+NWwv6ZeXxHApSWUUSsDuxNY93t9s3ma4Djadzbndeh0KRhM+H2qIh4NfAlYAfgWc3mR4Hzge9m5nBmMktdJyI2BT4E/DvwfGBBZq7e2aik9ky4PS4i+oDnNn+8LzMXdzIeabQ05yK8Fdg3M9/Z6Xikdky4kiQV4KQpSZIKMOFKklSACbdGImJeRMzrdBzS8vLvslZEJlxJkgow4UqSVIAJV5KkAky4kiQVYMKVJKkAE64kSQWYcCVJKsCEK0lSAV31LOWNP/v77glGGqHvfXqVTocgjYp3bLRrVHHcsRvuXcm/9QvmnFxJvKPFCleSpAJW6nQAkqR6abw1tH7qedWSJBVmhStJKipqWuvV86olSSrMCleSVFRd7+GacCVJRdU14dbzqiVJKswKV5JUVERXP5+iMla4kiQVYIUrSSqsnrWeCVeSVJSTpiRJUmWscCVJRVnhSpKkyljhSpKKquuzlE24kqSiHFKWJEmVscKVJBVlhStJkipjhStJKsoKV5IkVcYKV5JUVFDPtwWZcCVJRTmkLEmSKmOFK0kqygpXkiRVxoQrSSoqoq+Sbfliiq0iYkpE3BERj0TE1RHxxYhYdUC/nSNiRkQsiIh7IuKEiBg3nHOYcCVJhfVVtI1MRGwOXAJsBHwG2B04Hfg28KN+/SYCZwG3NvscCEwCpsYwMr73cCVJdfceYDVgj8y8sdl2fkT8C7B3RHwwM58AjgRmA3tl5mKAiLgTOAfYEzhlqJNY4UqSiurCIeUnmp8PDmh/sLlvUURMALYDJi9JtgCZeS5wO7BHu5OYcCVJdTcZmAv8MCI2jojnRMTbgPcD/9VMsFs0+85u8f1Z/fYPyiFlSVJRVS0Lioh57fpk5rgWbXMiYntgCnBTv13fycyvNv88vvk5t8Vh5wJbtzu3CVeSVFR02eBq817tGcBdwDuAecAbgC9FxOJ+SRcgBznMYO1PMeFKknpCq+p1mA4Hng1slZkLmm0XRATA1yLiJ8D9zfbxLb6/Nq0r36V0168ZkqSe14WTprYCru6XbJeYSSNPbg5c1Wxrda92S1rf212KCVeSVHd3AFtExLMGtL+q+Xl7Zt5GIwHv03/NbUTsCEygsW53SA4pS5KKag7VdpNjgN8B0yPiaBrLgSYCBwHnZeasZr+Daay5PTkiTgTWA44ALgNOa3cSE64kqahue3lBZk6JiJ2BLwI/ANYAbgG+CXyvX7/zI2I34FBgKvAwjZnNB2XmonbnMeFKkmovM88DzhtGv2nAtJGcw4QrSSqq25YFlVLPq5YkqTArXElSUd12D7eUel61JEmFWeFKkoqqa4VrwpUkFeWkKUmSVBkrXElSWTUdUq7nVUuSVJgVriSpKCdNSZJUQBe+vKCIev6aIUlSYVa4kqSiXBYkSZIqY4UrSSrKSVOSJJXgpClJklQVK1xJUlk1LfVqetmSJJVlhStJKst7uJIkqSpWuJKksmpa4ZpwJUll1XRstaaXLUlSWVa4kqSisqZDyla4kiQVYIUrSSqrngWuCVeSVFhfPTOuQ8qSJBVghStJKstJU5IkqSpWuJKksupZ4JpwJUmFOWlKkiRVxQpXklSWk6YkSVJVrHAlSWXVs8C1wpUkqQQrXElSWTWdpWzClSSVVc9865CyJEklWOFKkoryBfSSJKkyVriSpLKcNCVJUgH1zLcOKUuSVIIVriSpLCdNSZKkqphwJUll9UU12whFxEkRkUNsz+/Xd+eImBERCyLinog4ISLGDec8DilLksrqvhHlbwLHD2hbGZgO/D0z7wKIiInAWcAU4CvAesARwBYR8brMXDzUSUy4kqRay8wbgRv7t0XEO4GxwE/6NR8JzAb2WpJcI+JO4BxgT+CUoc7jkLIkqayIarbRtR/wKM0kGhETgO2Ayf0r2cw8F7gd2KPdAU24kiT1ExEvAN4M/CYzH2o2b9H8nN3iK7P67R+UQ8qSpLIqWhYUEfPa9cnMccM41PuBMSw9nDy++Tm3Rf+5wNbtDmqFK0nS0vYFbsjMi1rsy0G+M1j7U6xwJUllVVTqDbN6HVJEvBbYDPjygF33Nz/H80xr07ryXYoVriSprO6eNLUfsAj4+YD2q5qfre7Vbknre7tLMeFKkgRExOo0lvdMz8zb++/LzNuAmcA+EdHX7zs7AhOA09sd3yFlSVJZ3ffgiyX2AtYAfjrI/oNprLk9OSJO5OkHX1wGnNbu4Fa4kiQ1fAC4D/hDq52ZeT6wG7ARMBX4XvNz18xc1O7gVriSpKKyS19An5mvG0afacC0kRzfhCtJKqumr+cz4faw3baawKd32Yz1xo3l3ocX8oWT/8YdDyzg4q+9iUcWPvlUvxP+93qOPfe6DkYqDe7XR0zmxiuu5/HHFvLstZ7D6/d8I6/c9VXMvet+jnz/N1lltVWe6vuGd+/Ijvvs0sFopcGNSsKNiDWADTPz6tE4npbfazddhy/u9hL2/8VMrpzzAOs+ZzUAVmoO5bz8kLNYtLjtOm2p43bYayfe9dm9WWmVlbhnzt2ceNBxrLfJ+jzr2c8C4Ounf5cxY8Z0OEotk3oWuKM2aWoXGs+SVJf4zJs355hzruWKfz5AJtz94GPc/eBjnQ5LWmbP2+gFrLRKozZoLLcM5t5xX4ejkpadQ8o9qC9gyw3Gcd5Vd/F/h+zIqiuP4dxZd/KdM656qs/FX92ZBC6+9l6+e8ZVPPDI450LWGpjyrGn8ddz/8wTC59gvU3WZ7NXvoRHHpwPwBHvPQwCXrTVZrzlw5NYfc01Ohyt2urSSVNVM+H2oOc+ezVWWamPXV++Hu8+7mKeXJSc+MFXcsDOm/GD865j0vcu5OrbH2StZ63CYe96GUf/+za8/4RLOx22NKi3H7Ankz6xB3OuuYUb/34DK628EquvuQb7H/s5XvCvE3j0oUf5/XG/4ddHTOaD3/l4p8NVOzWdNFVsHW5EzGu3lYql1z32RGM52M//eBP3PrSQBx55nJ9ccCMTX7wujz6+iFm3zmPR4uS++Qv52m//zus3X5c1VvV3L3W3vjF9bLTFC3no3nnMOPNiVh27KutvuiFjxozh2Ws9m7d9cg+u/+u1PPaIt07UnfxXtgc9tOAJ7nhgwTDeXcFTfWr6C6dWQIsWL+b+O+9/5o6n/hI7GbDr1fTfmyETbkRMGuZxtmvXYThvcdj4s7/3v5RR8ps/z+F9r9uYC/9xN08sSvZ7w79y/tV384oN1+KhBU9w833zWXPsynz9nVty6fX38vBjT7Y/qFTY/HkPc+MV17P5/3spK6+yMjdcfi1X/t/feM8X38ucf9zC2NXHMn7COiyYv4AzfvBbXviyTVht9bGdDltqqV2FO4XGr4vD+X3EZNlFjj3nWtZafRXOP2QnFj6xiKlX3MFx517HLlu+gC+89cWMX2NV5i98kouvvZdPTf5rp8OVBhHMOPNP/O6YU8lMxq27Nrt/7B289NVbcsX//ZXpP5vK/HnzWW311dhkq03Z+0vv63TAGo6aTpqKzMHzZES8YVkOlpkXLk8wVrjqBd/79CrtO0krgHdstGslmfFfP3BqJf/W3/izd3d1Jh+ywl3eBCpJ0jPUtMIdtVnKEbH3aB1LktS7MqrZut1yJ9yIeHdEXAX8chTikSSpJ7VNuBFxSETcEhGPRsTlEfHmZvv2EXE5cDKwFvDJimOVJPWCvqhm63JDJtyI+BTwLeA5NJ6VvC4wJSI+DFwEbAJ8DdgkM4+vOFZJklZY7ZYF7QdcCOyemfMjog84BjgeuBbYJTNvrThGSVIvqemTdtoNKb8IODoz5wNk5mLguzTW5X7DZCtJWmYOKbc0FrhzQNtdzc+bRj8cSZJ603CepTzYAuVFoxmIJKkmir02p7sMJ+FOjohHW7T/T0Qs6PdzZuY2oxSXJEk9pV3CvYjWFa5PoJIkjUxNJ021e7TjxEJxSJLqYgWY4FSFdutwfxoRG5cKRpKkXtXu1vW+wDoF4pAk1URGVLJ1u5rOFZMkqazhzFKWJGn01LTUG07CfUtEbD6cg2XmL5YzHkmSetJwEu5XaTzKsZ0ETLiSpKHVdJbycBLu+4DZVQciSaqJFWCCUxWGk3Cvz8wrK49EkqQe5qQpSVJZNR1SrulcMUmSymqXcI8GPhoROw3WISJ2ioj/iojVRzUySVJvioq2Ltcu4d4DvBm4ZIg+lwB7AR8braAkSb0r+6KSrdu1S7hvA07MzFav5wOgue8EYI/RDEySpF7SLuG+BLh0GMeZ0ewrSdLQ+qKarcu1S7irAo8N4zgLgdWWPxxJknpTu4R7F7DZMI6zGXD38ocjSep5EdVsXa5dwr0I+FhEjBmsQ3PfR4ELRjEuSVKv6qto63LtQjwKeBlwWkQ8b+DOZtupzT5HjX54kiT1hiGfNJWZl0fEAcBxwFsjYiZwS3P3vwDbNo+xf2ZeUWGckqResQIM/1ah7aMdM/P4iPg78CVgB+BVzV2PAucA383M4cxkliSptob1LOXMvATYPSL6gOc2m+/LzMWVRSZJ6k0rwBKeKizTywuaCfaeimKRJKln+bYgSVJZVriSJFUvazppagVYuSRJ0orPhCtJKqtLH3wRERMj4pyImBcRj0bE1RHxkQF9do6IGRGxICLuiYgTImLccI5vwpUk1V5EvB84D7gReA+wO/B9YJV+fSYCZwG3NvcfCEwCpjZX8QzJe7iSpLK67B5uRGwA/BA4JDOP7Lfrfwd0PRKYDey1ZFlsRNxJ45kUewKnDHUeK1xJUlnd93q+DzY/jx2sQ0RMALYDJvd/BkVmngvczjDeCW/ClSTV3euBa4B3RsS1EbEoIm6LiMMjYsmQ8hbNz9ktvj+r3/5BOaQsSSqronW4ETGvXZ/MHNeieb3mdizwVeAq4I00Hmm8AbAPML7Zd26L788Ftm53bhOuJKnu+oBnA3tn5q+bbRdExFjgwIj4er++OcgxBmt/iglXklRWRXOmBqleh+N+4EXA9AHtZ9OYibx1sw88Xen2tzatK9+leA9XklRU9kUl23KYNUj7koMupjHMDK3v1W5J63u7SzHhSpLq7vTm51sGtL+FxlDxXzLzNmAmsE//NbcRsSMwod8xBuWQsiSprC5bh5uZ0yLibOD7EfFcnp409Wng+Mz8Z7PrwTTW3J4cESfSmGh1BHAZcFq785hwJUlqPLjiUOAgYB1gDvAVGg+7ACAzz4+I3Zr9pgIPA1OAgzJzUbsTmHAlSWV14ev5MvMRGhOkDmzTbxowbSTnMOFKksrqvnxbhJOmJEkqwApXklRUX01LvZpetiRJZVnhSpKK6rJVQcVY4UqSVIAVriSpqLpWuCZcSVJRUdOM65CyJEkFWOFKkoqqaYFrhStJUglWuJKkoupa4ZpwJUlFRU3HVmt62ZIklWWFK0kqqq5Dyla4kiQVYIUrSSqqC98/X4QJV5JUlEPKkiSpMla4kqSirHAlSVJlrHAlSUX5tiBJklQZK1xJUlF1fbSjCVeSVFRNR5QdUpYkqQQrXElSUVa4kiSpMla4kqSi6lrhmnAlSUXV9eUFDilLklSAFa4kqai6Dilb4UqSVIAVriSpqLpWuCZcSVJRUdNZUw4pS5JUgBWuJKmoug4pW+FKklSAFa4kqSgrXEmSVBkrXElSUXWtcE24kqSiaroqyCFlSZJKsMKVJBVV1yFlK1xJkgqwwpUkFRU1LfVMuJKkohxSliRJlTHhSpKKiohKtuWIZ2JE5CDb5gP67hwRMyJiQUTcExEnRMS44ZzHIWVJkhoOBi4a0HbLkj9ExETgLGAK8BVgPeAIYIuIeF1mLh7q4CZcSVJRXXwP97rMnDHE/iOB2cBeS5JrRNwJnAPsCZwy1MEdUpYkFRVRzVZtzDEB2A6Y3L+SzcxzgduBPdodw4QrSVLDCRHxZEQ8GBFnRsQ2/fZt0fyc3eJ7s/rtH5RDypKkoqqqRiNiXrs+mTmuRfODwNHABcBc4MXAF4E/RcQbMvMyYHyz79wW358LbN3u3F2VcG8+6sWdDkFabmM3/HqnQ5BGxYI5u3Y6hCIy83Lg8n5Nf4yIP9CoZr8N7NS/+2CHaXeerkq4kqTeV9XbggapXkd6rLsi4hxgUrPp/ubn+Bbd16Z15bsU7+FKktRaH09Xrlc1P1vdq92S1vd2n3EwSZKK6YtqttEUEc8HdgZmAGTmbcBMYJ+Ip58GHRE7AhOA09sd0yFlSVJRfdH2dmdREfEr4Cbgb8ADwOY0HoIxFvhSv64H01hze3JEnMjTD764DDit3XlMuJKkupsFvAc4AFidxv3aC4BvZeZTQ8WZeX5E7AYcCkwFHqbx1KmDMnNRu5OYcCVJRVU1aWqkMvNw4PBh9p0GTBvJebyHK0lSAVa4kqSi6lrpmXAlSUV126SpUur6i4YkSUVZ4UqSiuq2SVOlWOFKklSAFa4kqai6VnomXElSUQ4pS5KkyljhSpKKCpcFSZKkqljhSpKK8h6uJEmqjBWuJKmoulZ6JlxJUlE+S1mSJFXGCleSVJSTpiRJUmWscCVJRdW10jPhSpKKckhZkiRVxgpXklSUy4IkSVJlrHAlSUXV9R6uCVeSVFRdh1bret2SJBVlhStJKspJU5IkqTJWuJKkouo6acoKV5KkAqxwJUlF1bXCNeFKkoqq69BqXa9bkqSirHAlSUW5LEiSJFXGCleSVJSTpiRJKqCuQ6t1vW5JkoqywpUkFVXXIWUrXEmSCrDClSQVFTVdFmTClSQV5ZCyJEmqjBWuJKmoulZ6db1uSZKKssKVJBXls5QlSVJlrHAlSUXVdZayCVeSVFRdE65DypIk9RMR34iIjIgrWuzbOSJmRMSCiLgnIk6IiHHDOa4JV5JU1JiKttEQES8FDgbubrFvInAWcCuwO3AgMAmYGhFt86lDypIkAc2k+RPgx8CWwLgBXY4EZgN7Zebi5nfuBM4B9gROGer4VriSpKL6IivZRsFngfWBLw/cERETgO2AyUuSLUBmngvcDuzR7uBWuJKkorpx0lREvBA4DNgnMx+KeEaQWzQ/Z7f4+qx++wdlwpUk9YSImNeuT2aOa/G9AH4ETM/MKYN8dXzzc26LfXOBrdud24QrSSqqCyvcDwPbAi8ZRt/Bxq7bjmmbcCVJPaFV9dpORDyXxmSo7wKP9FvisxIwpvnzY8D9zfbxA48BrE3ryncpTpqSJBU1JqrZRmh9YE0aCfeBfttraNyXfQD4BnBVs3+re7Vb0vre7lKscCVJRXXZkPINwA4t2o8G1gA+BMzJzNsiYiawT0Qc3W9Z0I7ABOD0dicy4UqSaisz5wMXDGxfMgErM/vvO5jGmtuTI+JEYD3gCOAy4LR25zLhSpKKWlFfz5eZ50fEbsChwFTgYWAKcFBmLmr3fROuJEkDZObEQdqnAdNGckwTriSpqC67h1uMs5QlSSrACleSVNRovdlnRWPClSQV5ZCyJEmqjBWuJKmoFXVZ0PKywpUkqQArXElSUcvx3OMVmglXklSUk6YkSVJlrHAlSUVZ4UqSpMpY4UqSiqprhWvClSQVNcZ1uJIkqSpWuJKkoupa6dX1uiVJKsoKV5JUlJOmJEkqoK4J1yFlSZIKsMKVJBXlsiBJklQZK1xJUlHew5UkSZWxwpUkFVXXCteEK0kqqq4J1yFlSZIKsMKVJBU1xgpXkiRVxQpXklRUX00ffGHClSQVVdeh1bpetyRJRVnhSpKKclmQJEmqjBWuJKkolwWpp/zyl2fyznd+li22eAdf/OJRLfscd9zJbLbZ7lxyyRVlg5OWwYbrP5ffnXQQd8z6ETfP/CFHHbYvY8Y0/ukau9oqHP2t/bj1ihO5a/ZPOPe0r3U4Wg1HX2QlW7ezwu1R6667Np/4xLv54x8vZ+HChc/YP2fOnUyf/ifWWWftDkQnDd9/f2s/7r3/ITbe9hOMe86zOPNXh/DR9+3MD342ne8f/mFWWqmPrd74eebOm8/LX7pRp8OVBjVohRsREyLidS3aXxcRMyJifkRcFxH7VhqhRuRNb3o1O+30KsaNe3bL/YcddjwHHrgvq6zi71zqbhttsC6/PXMGCxc+wd33Psi5F1zJizddnxe98AW8deet+eQXf8x9cx9m8eLk8lk3dzpcDUNfVLN1u6GGlA8FlhqLjIiNgLOBbYFrgXHATyJi14riUwXOPvtiVl55Zd7whm07HYrU1vd/No09J72KsautwnrPW4s37fAKzr3gSrbbahPm3H4fX/3cu7j1ihP5yzlH8PZdX9npcKVBDZVwtwdOHdB2ADAWeFdmbgNsDMwEPtXuRBExr902wmvQMnjkkQUcddQvOOSQD3U6FGlY/jjjal686frcc/VPufEvP+Bvf7+JP0yfyYTnr80Wm2/Igw8/ygu3+zif/epJ/Oh7H2ezTdbrdMhqwwr3mdYDrh7Q9mbgmsycApCZjwDfB7apJDqNumOP/R8mTdqBDTZ4fqdDkdqKCM6Y/CV+f/ZfGL/5vkx42YcZt+bqfPuQf+Oxxx7n8cef5PBjfscTTyzi4suu4cJLr2Kn17+s02FLLQ2VcFcF5i/5ISLWBDYHLhzQ72ZgzXYnysxx7bYRxK9ldOmlVzJ58hm85jXv5TWveS933nkfn/nMEZx44m86HZr0DGuPW4MNJjyX438+nccff5K58+Yz+dQL2WWHVzDrH3M6HZ5GqK+irdsNFeMcYMt+P78WCOCSAf3WAOaNblhaXk8+uYiFCx9n8eLFLFq0mIULH+fJJxdx0knf4swzv8+UKccwZcoxrLvu2hx66CfZZ5+3djpk6Rnuf+Bhbp5zNx95786MGdPHms95Fv/+rtcz6+p/cvFl/+DWO+7jC598G2PG9PGqbTfl9du/hHMv/Hunw1YbEdVs3W6oKapnAgdFxEzgbuDLwEJg+oB+2wH/rCY8jdQPf3gKxx138lM//+EPF7D//ntzwAH/tlS/MWP6WHPNNVh99bGlQ5SG5T0fOYr/+Pr7+NzHd2fRouSiS6/ioMMm8+STi9jzQ//FD4/4MAd+YhJzbr+PD332B1x34x2dDllqKTJbLxaOiPHAn4GNljQBh2Tm4QP6/QM4IzO/sPzhXNf9K5elNsZu+PVOhyCNigVzTq6kbvzLvVMr+bd+u3Xe2tV17qAVbmbeHxEvB/YE1gZmZOaf+veJiHWBH9GohiVJ0iCGfOpBZs4HfjbE/nsi4pc0ZilfO8qxSZJ60Ipwv7UKo/GYodfSWK87ZhSOJUnqcSvCjOIq1PW6JUkCICJeHRHTI+L2iHgsIu6NiPNbPUUxInZuPt54QUTcExEnRMS44ZzHhCtJKioiK9mWw1o0bot+nsYDnj5CY1XOWRHxnqfjjonAWcCtwO7AgcAkYGpEtM2nPrleklRrmTkVmNq/LSLOoPFgp48Av242HwnMBvbKzMXNfncC59CYYHzKUOexwpUkFRUVbaMpM58EHgSegMYb9Gg8d2LykmTb7HcucDuwR7tjDlrhRkTbFxI0vXyY/SRJ6tpZys1h4T5gXeCjwKY0ho0Btmh+zm7x1Vn99g9qqCHlo4cdJfjACklSRw3nrXNtntt/Kk9Xqg8B787Mac2fxzc/57b43lxg63bnHirhbtzuy/2sugx9JUk11qUFLsBBwBHA84F/A06NiPdn5sn9+gxWYLYtPId60lTb5yNHxCuA/YC9gXXa9ZckqSrL+9a5zLwJuKn54xnNiVPfj4hTgPub7eNbfHVtWle+S1nmSVMRsVZE7B8RfwP+CuxPY/xakqS2VqAX0P+ZxpKhdYCrmm2t7tVuSet7u0sZdsKNiDdFxK+BO4BjaEyWOgnYNDPfONzjSJLU7SIigIk0Xj97f2beBswE9um/5jYidgQmAKe3O+aQ63AjYmPgA8D7gfWBRTTWKv0W+AXw88y8YQTXIkmqqW67hxsRv6Lxmtm/AvcBL6CR994IHNBcIgRwMI01tydHxInAejTu+V4GnNbuPEMtCzofeD2N/2+uBr5AY/3RvRGx5givS5JUc124LOhSYB8aS4HWpLH+diYwKTPPWNIpM8+PiN2AQ2kUnw8DU4CDMnNRu5MMVeFOpDHr6gwaGf7WEV2GJEldLDOPA44bZt9pwLS2HVsY6h7uV4AbaDwn8ubmg53fExEuAZIkjdiK8KSpKgyacDPzO5m5GY1K95fAq4FfAXfRmDSV+MALSZKGpe0s5cy8KDP3pbEQ+KPANcB7afxCcXxEHDDcVxNJkmSF20ZmPpKZP87MVwObA/9JY33Sf9N4cLMkSW2tQOtwR9WI3haUmddl5kHABsDbgemjGZQkSb1mud6H25wG/YfmJklSWytAMVoJ34crSVIBy1XhSpK0rCLqucDFhCtJKsohZUmSVBkrXElSUV34LOUirHAlSSrACleSVFRdK726XrckSUVZ4UqSiqrrPVwTriSpqJrmW4eUJUkqwQpXklRUXYeUrXAlSSrACleSVFRNC1wTriSprBXhZfFVcEhZkqQCrHAlSUXVtMC1wpUkqQQrXElSUb6AXpKkAhxSliRJlbHClSQV5ZOmJElSZaxwJUlF1bTAtcKVJKkEK1xJUlF1rfRMuJKkopw0JUmSKmOFK0kqrJ4lrhWuJEkFWOFKkoqKmla4JlxJUlER9RxcredVS5JUmBWuJKmweg4pW+FKklSAFa4kqSgnTUmSVEQ9E65DypIkFWCFK0kqymVBkiSpMla4kqTCvIcrSZIqYsKVJBUVFf1vxPFE7BgRJ0XEtRHxaETcFhGnR8SWLfruHBEzImJBRNwTESdExLjhnMeEK0kqqtsSLvAxYEPgKGBX4HPNn/8SEds/FXfEROAs4FZgd+BAYBIwNYYxE8x7uJKkuvtkZt7TvyEizgFuBr4A7NFsPhKYDeyVmYub/e4EzgH2BE4Z6iRWuJKkwvoq2kZmYLJtts0DrgfWB4iICcB2wOQlybbZ71zgdp5OyoMy4UqSNEBErANsQaOipfln+v3c36x++wflkLIkqaiIapYFRcS8dn0yc9wwjhPAiTSK0v9sNo9vfs5t8ZW5wNbtjmvClSQV1vXrcP8DeDvwgcy8ZsC+HOQ7g7U/xYQrSeoJw6le24mIbwOfBz6dmSf123V/83P8M74Ea9O68l2K93AlSUV14bKgRlwRhwGHAAdl5jEDdl/V/Gx1r3ZLWt/bXYoJV5JUexHxdeCrwFcz8z8G7s/M24CZwD7919xGxI7ABOD0dudwSFmSVFh31XoR8XngG8CZwHn9H3YBLMzMy5t/PpjGmtuTI+JEYD3gCOAy4LR25zHhSpKKGo3h31G2e/Nzt+bW3z+BjQAy8/yI2A04FJgKPAxMoTEEvajdSUy4kqRay8yJy9B3GjBtJOcx4UqSiqpqHW63666BdEmSepQVriSpMCtcSZJUEStcSVJRUdNaz4QrSSrMIWVJklQRK1xJUlEuC5IkSZWxwpUkFVbPCteEK0kqqq6zlOt51ZIkFWaFK0kqrJ5Dyla4kiQVYIUrSSqqC9+HW4QJV5JUlOtwJUlSZaxwJUmF1bPWq+dVS5JUmBWuJKmouk6assKVJKkAK1xJUmH1rHBNuJKkolwWJEmSKmOFK0kqrJ61Xj2vWpKkwqxwJUlF1XVZUGRmp2OQJKnnOaQsSVIBJlxJkgow4UqSVIAJV5KkAky4kiQVYMKVJKmA/w9wNjDmGdEUlwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "sns.set_context(\"talk\", rc={\"font\":\"Helvetica\", \"font.size\":12})\n",
    "label = [\"CTRL\", \"ALS\"]\n",
    "cm = confusion_matrix(y, y_hat, labels=[0, 1])\n",
    "plt.figure(figsize=(8, 8))\n",
    "cm = 100 * cm / cm.sum(axis=1)[:,np.newaxis]\n",
    "ax = sns.heatmap(cm, annot=True, cmap='YlGnBu', fmt='0.0f',\n",
    "                 xticklabels=label, yticklabels=label)\n",
    "ax.xaxis.tick_top()\n",
    "plt.xticks(rotation=90) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-highway",
   "metadata": {},
   "source": [
    "## Some comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-finnish",
   "metadata": {},
   "source": [
    "The accuracy is corely correlated to the number of samples -> unbalanced data \n",
    "\n",
    "If the model is finetuned with a lot of ALS samples it will be bad to predict on CTRL data ! (the inverse is rare/ impossible due to unbalancement !)\n",
    "\n",
    "We could have created a custom split on the number of samples but the effort would have been useless regarding the fact that we have to keep samples per patients and the number is highly variable -> 70 >> 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-design",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
